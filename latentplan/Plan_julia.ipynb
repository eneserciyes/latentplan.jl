{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418a34c5-1db5-4c09-b71b-6272b221c84b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import Pkg\n",
    "Pkg.activate(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d23e807-98c0-49fa-95d1-8b8d20f044d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "using ArgParse: ArgParseSettings, @add_arg_table!, parse_args\n",
    "using Statistics: mean\n",
    "using Printf\n",
    "using Knet\n",
    "using Debugger: @enter, @bp, @run\n",
    "using JSON\n",
    "using PyCall\n",
    "\n",
    "include(\"LPCore.jl\")\n",
    "include(\"setup.jl\")\n",
    "\n",
    "s = ArgParseSettings()\n",
    "@add_arg_table! s begin\n",
    "    \"--dataset\"\n",
    "        help = \"which environment to use\"\n",
    "        arg_type = String\n",
    "        default = \"halfcheetah-medium-expert-v2\"\n",
    "    \"--exp_name\"\n",
    "        help = \"name of the experiment\"\n",
    "        arg_type = String\n",
    "        default = \"debug\"\n",
    "    \"--seed\"\n",
    "        help = \"seed\"\n",
    "        default = 42\n",
    "    \"--beam_width\"\n",
    "        default = 64\n",
    "    \"--n_expand\"\n",
    "        default = 4\n",
    "    \"--suffix\"\n",
    "        default = \"\"\n",
    "    \"--config\"\n",
    "        help = \"relative jl file path with configurations\"\n",
    "        arg_type = String\n",
    "        default = \"../config/vqvae.jl\"\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ddbdba-d4ef-4823-ad70-27c3849ed399",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@pyimport torch\n",
    "@pyimport numpy\n",
    "@pyimport random\n",
    "\n",
    "seed = 42\n",
    "numpy.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "weights = torch.load(\"test/files/gpt_trained.pt\", map_location=torch.device(\"cpu\"))\n",
    "prior_weights = torch.load(\"test/files/prior_trained.pt\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702a6c07-4a9e-413b-8b28-f8e482835a3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#######################\n",
    "####### setup ########\n",
    "#######################\n",
    "\n",
    "super_args = Dict{String, Any}(\n",
    "    \"dataset\"=> \"hopper-medium-replay-v2\",\n",
    "    \"exp_name\"=> \"T-1-42\",\n",
    "    \"seed\"=> 42,\n",
    "    \"config\"=> \"../config/vqvae.jl\",\n",
    "    \"beam_width\"=>64,\n",
    "    \"n_expand\"=>4,\n",
    "    \"suffix\"=>\"\"\n",
    ")\n",
    "args = parser(super_args, experiment=\"plan\")\n",
    "\n",
    "args[\"logbase\"] = expanduser(args[\"logbase\"])\n",
    "args[\"savepath\"] = expanduser(args[\"savepath\"])\n",
    "args[\"loadpath\"] = joinpath(args[\"logbase\"], args[\"dataset\"], args[\"exp_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebef0c4d-9e0f-4515-9998-4128aca974e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "env = load_environment(args[\"dataset\"])\n",
    "dataset_config = Knet.load(joinpath(args[\"loadpath\"] , \"dataset_config.jld2\"), \"config\")\n",
    "\n",
    "dataset = SequenceDataset(\n",
    "    dataset_config[\"env_name\"];\n",
    "    penalty=dataset_config[\"penalty\"],\n",
    "    sequence_length=dataset_config[\"sequence_length\"], \n",
    "    step=dataset_config[\"step\"], \n",
    "    discount=dataset_config[\"discount\"], \n",
    "    disable_goal=dataset_config[\"disable_goal\"], \n",
    "    normalize_raw=dataset_config[\"normalize_raw\"], \n",
    "    normalize_reward=dataset_config[\"normalize_reward\"],\n",
    "    max_path_length=dataset_config[\"max_path_length\"],\n",
    "    atype=dataset_config[\"atype\"]\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948dca42-88ee-44dc-8fa6-53ddcef44d1c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Representation model init and weight loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00895a8-6bb3-4ff4-9e71-4fe99faa9509",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_config = Knet.load(joinpath(\"/Users/mehmeteneserciyes/logs_julia/hopper-medium-replay-v2/T-1-42\", \"model_config.jld2\"), \"config\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5010a8-4149-4928-a851-1582b90b21cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gpt = VQContinuousVAE(model_config);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b3ea2f-8bf2-4343-90af-cab9a7516f18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# encoder\n",
    "gpt.model.embed.w = Param(atype(weights[\"model.embed.weight\"][:cpu]()[:numpy]()))\n",
    "gpt.model.embed.b = Param(atype(weights[\"model.embed.bias\"][:cpu]()[:numpy]()))\n",
    "\n",
    "gpt.model.pos_emb = Param(atype(permutedims(weights[\"model.pos_emb\"][:cpu]()[:numpy](), (3,2,1))))\n",
    "\n",
    "for i in 1:model_config[\"n_layer\"]\n",
    "    gpt.model.encoder.layers[i].ln1.a = Param(atype(weights[\"model.encoder.$(i-1).ln1.weight\"][:cpu]()[:numpy]()))\n",
    "    gpt.model.encoder.layers[i].ln1.b = Param(atype(weights[\"model.encoder.$(i-1).ln1.bias\"][:cpu]()[:numpy]()))\n",
    "    gpt.model.encoder.layers[i].ln2.a = Param(atype(weights[\"model.encoder.$(i-1).ln2.weight\"][:cpu]()[:numpy]()))\n",
    "    gpt.model.encoder.layers[i].ln2.b = Param(atype(weights[\"model.encoder.$(i-1).ln2.bias\"][:cpu]()[:numpy]()))\n",
    "\n",
    "    gpt.model.encoder.layers[i].attn.key.w = Param(atype(weights[\"model.encoder.$(i-1).attn.key.weight\"][:cpu]()[:numpy]()))\n",
    "    gpt.model.encoder.layers[i].attn.key.b = Param(atype(weights[\"model.encoder.$(i-1).attn.key.bias\"][:cpu]()[:numpy]()))\n",
    "    gpt.model.encoder.layers[i].attn.query.w = Param(atype(weights[\"model.encoder.$(i-1).attn.query.weight\"][:cpu]()[:numpy]()))\n",
    "    gpt.model.encoder.layers[i].attn.query.b = Param(atype(weights[\"model.encoder.$(i-1).attn.query.bias\"][:cpu]()[:numpy]()))\n",
    "    gpt.model.encoder.layers[i].attn.value.w = Param(atype(weights[\"model.encoder.$(i-1).attn.value.weight\"][:cpu]()[:numpy]()))\n",
    "    gpt.model.encoder.layers[i].attn.value.b = Param(atype(weights[\"model.encoder.$(i-1).attn.value.bias\"][:cpu]()[:numpy]()))\n",
    "    gpt.model.encoder.layers[i].attn.proj.w = Param(atype(weights[\"model.encoder.$(i-1).attn.proj.weight\"][:cpu]()[:numpy]()))\n",
    "    gpt.model.encoder.layers[i].attn.proj.b = Param(atype(weights[\"model.encoder.$(i-1).attn.proj.bias\"][:cpu]()[:numpy]()))\n",
    "\n",
    "    gpt.model.encoder.layers[i].mlp.layers[1].w = Param(atype(weights[\"model.encoder.$(i-1).mlp.0.weight\"][:cpu]()[:numpy]()))\n",
    "    gpt.model.encoder.layers[i].mlp.layers[1].b = Param(atype(weights[\"model.encoder.$(i-1).mlp.0.bias\"][:cpu]()[:numpy]()))\n",
    "    gpt.model.encoder.layers[i].mlp.layers[3].w = Param(atype(weights[\"model.encoder.$(i-1).mlp.2.weight\"][:cpu]()[:numpy]()))\n",
    "    gpt.model.encoder.layers[i].mlp.layers[3].b = Param(atype(weights[\"model.encoder.$(i-1).mlp.2.bias\"][:cpu]()[:numpy]()))\n",
    "end\n",
    "\n",
    "gpt.model.cast_embed.w = Param(atype(weights[\"model.cast_embed.weight\"][:cpu]()[:numpy]()))\n",
    "gpt.model.cast_embed.b = Param(atype(weights[\"model.cast_embed.bias\"][:cpu]()[:numpy]()))\n",
    "\n",
    "# Decoder\n",
    "gpt.model.latent_mixing.w = Param(atype(weights[\"model.latent_mixing.weight\"][:cpu]()[:numpy]()))\n",
    "gpt.model.latent_mixing.b = Param(atype(weights[\"model.latent_mixing.bias\"][:cpu]()[:numpy]()))\n",
    "\n",
    "for i in 1:model_config[\"n_layer\"]\n",
    "    gpt.model.decoder.layers[i].ln1.a = Param(atype(weights[\"model.decoder.$(i-1).ln1.weight\"][:cpu]()[:numpy]()))\n",
    "    gpt.model.decoder.layers[i].ln1.b = Param(atype(weights[\"model.decoder.$(i-1).ln1.bias\"][:cpu]()[:numpy]()))\n",
    "    gpt.model.decoder.layers[i].ln2.a = Param(atype(weights[\"model.decoder.$(i-1).ln2.weight\"][:cpu]()[:numpy]()))\n",
    "    gpt.model.decoder.layers[i].ln2.b = Param(atype(weights[\"model.decoder.$(i-1).ln2.bias\"][:cpu]()[:numpy]()))\n",
    "\n",
    "    gpt.model.decoder.layers[i].attn.key.w = Param(atype(weights[\"model.decoder.$(i-1).attn.key.weight\"][:cpu]()[:numpy]()))\n",
    "    gpt.model.decoder.layers[i].attn.key.b = Param(atype(weights[\"model.decoder.$(i-1).attn.key.bias\"][:cpu]()[:numpy]()))\n",
    "    gpt.model.decoder.layers[i].attn.query.w = Param(atype(weights[\"model.decoder.$(i-1).attn.query.weight\"][:cpu]()[:numpy]()))\n",
    "    gpt.model.decoder.layers[i].attn.query.b = Param(atype(weights[\"model.decoder.$(i-1).attn.query.bias\"][:cpu]()[:numpy]()))\n",
    "    gpt.model.decoder.layers[i].attn.value.w = Param(atype(weights[\"model.decoder.$(i-1).attn.value.weight\"][:cpu]()[:numpy]()))\n",
    "    gpt.model.decoder.layers[i].attn.value.b = Param(atype(weights[\"model.decoder.$(i-1).attn.value.bias\"][:cpu]()[:numpy]()))\n",
    "    gpt.model.decoder.layers[i].attn.proj.w = Param(atype(weights[\"model.decoder.$(i-1).attn.proj.weight\"][:cpu]()[:numpy]()))\n",
    "    gpt.model.decoder.layers[i].attn.proj.b = Param(atype(weights[\"model.decoder.$(i-1).attn.proj.bias\"][:cpu]()[:numpy]()))\n",
    "\n",
    "    gpt.model.decoder.layers[i].mlp.layers[1].w = Param(atype(weights[\"model.decoder.$(i-1).mlp.0.weight\"][:cpu]()[:numpy]()))\n",
    "    gpt.model.decoder.layers[i].mlp.layers[1].b = Param(atype(weights[\"model.decoder.$(i-1).mlp.0.bias\"][:cpu]()[:numpy]()))\n",
    "    gpt.model.decoder.layers[i].mlp.layers[3].w = Param(atype(weights[\"model.decoder.$(i-1).mlp.2.weight\"][:cpu]()[:numpy]()))\n",
    "    gpt.model.decoder.layers[i].mlp.layers[3].b = Param(atype(weights[\"model.decoder.$(i-1).mlp.2.bias\"][:cpu]()[:numpy]()))\n",
    "end\n",
    "\n",
    "gpt.model.ln_f.a = Param(atype(weights[\"model.ln_f.weight\"][:cpu]()[:numpy]()))\n",
    "gpt.model.ln_f.b = Param(atype(weights[\"model.ln_f.bias\"][:cpu]()[:numpy]()))\n",
    "\n",
    "gpt.model.predict.w = Param(atype(weights[\"model.predict.weight\"][:cpu]()[:numpy]()))\n",
    "gpt.model.predict.b = Param(atype(weights[\"model.predict.bias\"][:cpu]()[:numpy]()))\n",
    "\n",
    "# codebook\n",
    "gpt.model.codebook.embedding = Param(atype(weights[\"model.codebook.embedding\"][:cpu]()[:numpy]()'))\n",
    "gpt.model.codebook.ema_count = Param(atype(weights[\"model.codebook.ema_count\"][:cpu]()[:numpy]()))\n",
    "gpt.model.codebook.ema_w = Param(atype(weights[\"model.codebook.ema_w\"][:cpu]()[:numpy]()'))\n",
    "\n",
    "# padding vector\n",
    "gpt.padding_vector = atype(normalize_joined_single(dataset, atype(zeros(gpt.transition_dim-1))));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f93455-c04b-46de-b8b1-62cd77cff421",
   "metadata": {
    "tags": []
   },
   "source": [
    "# TransformerPrior Init and Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a84589a-35c6-41f4-b85d-624c491921d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "args = parser(super_args, experiment=\"train\")\n",
    "args[\"logbase\"] = expanduser(args[\"logbase\"])\n",
    "args[\"savepath\"] = expanduser(args[\"savepath\"])\n",
    "args[\"savepath\"] = \"/Users/mehmeteneserciyes/logs_julia/hopper-medium-replay-v2/T-1-42/\"\n",
    "block_size = args[\"subsampled_sequence_length\"] ÷ args[\"latent_step\"]\n",
    "obs_dim = dataset.observation_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8b3295-0841-470a-a435-82cc90b60d38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_config = deepcopy(args)\n",
    "model_config[\"block_size\"] = block_size\n",
    "model_config[\"observation_dim\"] = obs_dim\n",
    "model_config[\"n_embd\"] = args[\"n_embd\"] * args[\"n_head\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8e6975-9f21-4d31-8277-e6a426bd278b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# turn off dropout\n",
    "model_config[\"embd_pdrop\"] = 0.0f0\n",
    "model_config[\"attn_pdrop\"] = 0.0f0\n",
    "model_config[\"resid_pdrop\"] = 0.0f0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae486b8a-8a46-47c6-94fe-5f33039f6283",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prior = TransformerPrior(model_config);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413a9612-295f-4d83-a5b4-34db1b432001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder\n",
    "prior.tok_emb = Param(atype(prior_weights[\"tok_emb.weight\"][:cpu]()[:numpy]()'))\n",
    "prior.pos_emb = Param(atype(permutedims(prior_weights[\"pos_emb\"][:cpu]()[:numpy](), (3,2,1))))\n",
    "\n",
    "prior.state_emb.w = Param(atype(prior_weights[\"state_emb.weight\"][:cpu]()[:numpy]()))\n",
    "prior.state_emb.b = Param(atype(prior_weights[\"state_emb.bias\"][:cpu]()[:numpy]()))\n",
    "\n",
    "for i in 1:model_config[\"n_layer\"]\n",
    "    prior.blocks.layers[i].ln1.a = Param(atype(prior_weights[\"blocks.$(i-1).ln1.weight\"][:cpu]()[:numpy]()))\n",
    "    prior.blocks.layers[i].ln1.b = Param(atype(prior_weights[\"blocks.$(i-1).ln1.bias\"][:cpu]()[:numpy]()))\n",
    "    prior.blocks.layers[i].ln2.a = Param(atype(prior_weights[\"blocks.$(i-1).ln2.weight\"][:cpu]()[:numpy]()))\n",
    "    prior.blocks.layers[i].ln2.b = Param(atype(prior_weights[\"blocks.$(i-1).ln2.bias\"][:cpu]()[:numpy]()))\n",
    "\n",
    "    prior.blocks.layers[i].attn.key.w = Param(atype(prior_weights[\"blocks.$(i-1).attn.key.weight\"][:cpu]()[:numpy]()))\n",
    "    prior.blocks.layers[i].attn.key.b = Param(atype(prior_weights[\"blocks.$(i-1).attn.key.bias\"][:cpu]()[:numpy]()))\n",
    "    prior.blocks.layers[i].attn.query.w = Param(atype(prior_weights[\"blocks.$(i-1).attn.query.weight\"][:cpu]()[:numpy]()))\n",
    "    prior.blocks.layers[i].attn.query.b = Param(atype(prior_weights[\"blocks.$(i-1).attn.query.bias\"][:cpu]()[:numpy]()))\n",
    "    prior.blocks.layers[i].attn.value.w = Param(atype(prior_weights[\"blocks.$(i-1).attn.value.weight\"][:cpu]()[:numpy]()))\n",
    "    prior.blocks.layers[i].attn.value.b = Param(atype(prior_weights[\"blocks.$(i-1).attn.value.bias\"][:cpu]()[:numpy]()))\n",
    "    prior.blocks.layers[i].attn.proj.w = Param(atype(prior_weights[\"blocks.$(i-1).attn.proj.weight\"][:cpu]()[:numpy]()))\n",
    "    prior.blocks.layers[i].attn.proj.b = Param(atype(prior_weights[\"blocks.$(i-1).attn.proj.bias\"][:cpu]()[:numpy]()))\n",
    "\n",
    "    prior.blocks.layers[i].mlp.layers[1].w = Param(atype(prior_weights[\"blocks.$(i-1).mlp.0.weight\"][:cpu]()[:numpy]()))\n",
    "    prior.blocks.layers[i].mlp.layers[1].b = Param(atype(prior_weights[\"blocks.$(i-1).mlp.0.bias\"][:cpu]()[:numpy]()))\n",
    "    prior.blocks.layers[i].mlp.layers[3].w = Param(atype(prior_weights[\"blocks.$(i-1).mlp.2.weight\"][:cpu]()[:numpy]()))\n",
    "    prior.blocks.layers[i].mlp.layers[3].b = Param(atype(prior_weights[\"blocks.$(i-1).mlp.2.bias\"][:cpu]()[:numpy]()))\n",
    "end\n",
    "\n",
    "prior.ln_f.a = Param(atype(prior_weights[\"ln_f.weight\"][:cpu]()[:numpy]()))\n",
    "prior.ln_f.b = Param(atype(prior_weights[\"ln_f.bias\"][:cpu]()[:numpy]()))\n",
    "# no bias\n",
    "prior.head.w = Param(atype(prior_weights[\"head.weight\"][:cpu]()[:numpy]())); "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43657dc4-82d5-4ecb-a8ba-ffc754028cf8",
   "metadata": {},
   "source": [
    "# Planning part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa00fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parser(super_args, experiment=\"plan\")\n",
    "args[\"logbase\"] = expanduser(args[\"logbase\"])\n",
    "args[\"savepath\"] = expanduser(args[\"savepath\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5954afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "observation_gt = numpy.load(\"test/files/plan_observation.npy\")\n",
    "state_gt = numpy.load(\"test/files/plan_state.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735424ee-dd80-4de3-9ed6-e259c7499ef2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "discount = dataset.discount\n",
    "observation_dim = dataset.observation_dim\n",
    "action_dim = dataset.action_dim\n",
    "\n",
    "#######################\n",
    "###### main loop ######\n",
    "#######################\n",
    "REWARD_DIM = VALUE_DIM = 1\n",
    "transition_dim = observation_dim + action_dim + REWARD_DIM + VALUE_DIM\n",
    "\n",
    "observation = observation_gt\n",
    "total_reward = 0\n",
    "discount_return = 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "af1c83b4",
   "metadata": {},
   "source": [
    "# Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ae1533",
   "metadata": {},
   "outputs": [],
   "source": [
    "t=0;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7beda0-60a1-40df-885f-a1a97239b357",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rollout = [deepcopy(state_gt)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0350c1-28f5-4939-90a4-3444587d315f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## previous (tokenized) transitions for conditioning transformer\n",
    "context = []\n",
    "mses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20c0a3b-55a9-4cfe-93e7-58fe5e7c6c81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "T = env.max_episode_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1c9e13-6366-44d3-9e5d-445cb18c4fd0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "observation = observation_gt;\n",
    "state = state_gt;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdec5d3-e6dc-4122-84f4-6c1f88762246",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if dataset.normalized_raw\n",
    "    println(\"normalize\")\n",
    "    observation = normalize_states(dataset, observation) # TODO: implement normalize_states\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b8db37",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#######################\n",
    "####### util functions ########\n",
    "#######################\n",
    "\n",
    "function make_prefix(obs, transition_dim)\n",
    "    obs_discrete = atype(obs)\n",
    "    pad_dims = atype(zeros(transition_dim - size(obs_discrete, 1)))\n",
    "    if ndims(obs_discrete) == 2\n",
    "        obs_discrete = reshape(obs_discrete, :, 1, 1)\n",
    "        pad_dims = reshape(pad_dims, :, 1, 1)\n",
    "    end\n",
    "    transition = cat(obs_discrete, pad_dims, dims=1)\n",
    "    prefix = transition\n",
    "    return prefix\n",
    "end\n",
    "\n",
    "function extract_actions(x, observation_dim, action_dim; t=nothing)\n",
    "    actions =  x[observation_dim+1:observation_dim+action_dim, :]\n",
    "    if t !== nothing\n",
    "        return actions[:, t]\n",
    "    else\n",
    "        return actions\n",
    "    end\n",
    "end\n",
    "\n",
    "VALUE_PLACEHOLDER = 1e6\n",
    "function update_context(observation, action, reward)\n",
    "    rew_val = [reward; VALUE_PLACEHOLDER]\n",
    "    transition = cat(observation, action, rew_val; dims=1)\n",
    "    context = []\n",
    "    transition_discrete = atype(transition)\n",
    "    transition_discrete = reshape(transition_discrete, :, 1, 1)\n",
    "    push!(context, transition_discrete)\n",
    "    return context\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c080946f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = make_prefix(observation, transition_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef59c42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = beam_with_prior(prior, gpt, prefix, dataset, \n",
    "                discount=discount, \n",
    "                steps=args[\"horizon\"],\n",
    "                beam_width=args[\"beam_width\"],\n",
    "                n_expand=args[\"n_expand\"],\n",
    "                likelihood_weight=args[\"prob_weight\"],\n",
    "                prob_threshold=args[\"prob_threshold\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e90b173",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_value = denormalize_values(dataset, sequence[end-1, 1])\n",
    "first_search_value = denormalize_values(dataset, sequence[end-1,end])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebeae54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_recon = sequence\n",
    "## [ action_dim ] index into sampled latentplan to grab first action\n",
    "feature_dim = dataset.observation_dim\n",
    "action = extract_actions(sequence_recon, feature_dim, action_dim; t=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f7044c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset.normalized_raw\n",
    "    action = reshape(denormalize_actions(dataset, action), :)\n",
    "    sequence_recon = denormalize_joined(dataset, sequence_recon)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931b9dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_observation, reward, terminal, _ = env.step(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad98a2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_reward += reward\n",
    "discount_return += reward * (discount ^ (t-1))\n",
    "score = env.get_normalized_score(total_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4b2e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "push!(rollout, deepcopy(state))\n",
    "context = update_context(observation, action, reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba4f3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "@printf(\"[ plan ] t: %d / %d | r: %.2f | R: %.2f | score: %.4f | time: | %s | %s | %s\\n\", \n",
    "t, T, reward, total_reward, score,\n",
    "args[\"dataset\"], args[\"exp_name\"], args[\"suffix\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f6e1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path = joinpath(args[\"savepath\"], \"rollout.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde97f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data = Dict(\n",
    "    \"score\" => score,\n",
    "    \"step\" => t,\n",
    "    \"return\" => total_reward,\n",
    "    \"term\" => terminal,\n",
    "    \"gpt_epoch\" => 123,\n",
    "    \"first_value\" => first_value,\n",
    "    \"first_search_value\" => first_search_value,\n",
    "    \"discount_return\" => discount_return,\n",
    "    # \"prediction_error\" => mean(mses)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fb65dbea",
   "metadata": {},
   "source": [
    "# Beam with prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f3bd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior=prior\n",
    "model=gpt\n",
    "x=prefix\n",
    "dataset=dataset\n",
    "discount=discount;\n",
    "steps=args[\"horizon\"]\n",
    "beam_width=args[\"beam_width\"]\n",
    "n_expand=args[\"n_expand\"]\n",
    "likelihood_weight=args[\"prob_weight\"]\n",
    "prob_threshold=args[\"prob_threshold\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe5d8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "contex = nothing\n",
    "state = x[1:prior.observation_dim, 1, :]\n",
    "acc_probs = atype(zeros(1))\n",
    "info = Dict();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a856b69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f112a9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for loop starts\n",
    "step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e590de01",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits, _ = prior(contex, state)\n",
    "probs = softmax(logits[:, end, :], dims=1)\n",
    "log_probs = log.(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c70ceaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065c46bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_probs_gt = numpy.load(\"test/files/plan_log_probs.npy\")'\n",
    "all(log_probs .≈ log_probs_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd33ca0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_samples = step==0 ? beam_width * n_expand : n_expand\n",
    "samples = torch.multinomial(torch.tensor(probs'), num_samples=nb_samples, replacement=true).numpy()' .+ 1\n",
    "# samples = numpy.load(\"test/files/plan_samples.npy\")' .+ 1\n",
    "samples_log_prob = [reshape(a[i], size(a[i])..., 1) for (a, i) in zip(eachslice(log_probs, dims=2), eachslice(samples, dims=2))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5906909b",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_log_prob_gt = numpy.load(\"test/files/plan_samples_log_prob.npy\")'\n",
    "all(samples_log_prob .≈ samples_log_prob_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21874921",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_probs = repeat_interleave(acc_probs, nb_samples) .+ reshape(samples_log_prob, :)\n",
    "contex = reshape(samples, step+1, :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8feadf0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_raw = decode_from_indices(model, contex, state)\n",
    "prediction = reshape(prediction_raw, model.action_dim+model.observation_dim+3, :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e935e0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_t = prediction[end-2, :]\n",
    "V_t = prediction[end-1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bb8518",
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset !== nothing\n",
    "    r_t = reshape(denormalize_rewards(dataset, r_t), :, size(contex, ndims(contex)))\n",
    "end\n",
    "if dataset !== nothing\n",
    "    V_t = reshape(denormalize_values(dataset, V_t), :, size(contex, ndims(contex)))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb90f25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "discounts = cumprod(atype(ones(size(r_t)...)) .* discount, dims=1)\n",
    "values = dropdims_n(sum(r_t[1:end-1, :] .* discounts[1:end-1, :], dims=1), dims=(1,)) .+ V_t[end, :] .* discounts[end, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca762d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood_bonus = likelihood_weight .* clip(acc_probs, -1e5, log(prob_threshold)*(steps÷model.latent_step))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6692b249",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_top = step < steps ÷ model.latent_step - 1 ? beam_width : 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51646b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "values_with_b, index = torch.topk(torch.tensor(values.+likelihood_bonus), nb_top)\n",
    "values_with_b = values_with_b.numpy()\n",
    "index = index.numpy()\n",
    "index.+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16f4fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "info[(step+1)*model.latent_step] = Dict(\n",
    "            \"predictions\"=>cputype(prediction_raw),\n",
    "            \"returns\"=>cputype(values),\n",
    "            \"latent_codes\"=>cputype(contex),\n",
    "            \"log_probs\"=>cputype(acc_probs),\n",
    "            \"objectives\"=>cputype(values.+likelihood_bonus),\n",
    "            \"index\"=>cputype(index),\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd84f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "contex = contex[:, index]\n",
    "acc_probs = acc_probs[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aad63a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal = prediction_raw[:,:,index[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fd77c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "size(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6159ab74",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"predicted max value $(values[1])\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.5",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
