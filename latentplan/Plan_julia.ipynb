{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "418a34c5-1db5-4c09-b71b-6272b221c84b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `~/Projects/latentplan.jl`\n"
     ]
    }
   ],
   "source": [
    "import Pkg\n",
    "Pkg.activate(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0d23e807-98c0-49fa-95d1-8b8d20f044d0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: replacing module VQVAEConfig.\n"
     ]
    }
   ],
   "source": [
    "using ArgParse: ArgParseSettings, @add_arg_table!, parse_args\n",
    "using Statistics: mean\n",
    "using Printf\n",
    "using Knet\n",
    "using Debugger: @enter, @bp, @run\n",
    "using JSON\n",
    "using PyCall\n",
    "\n",
    "include(\"LPCore.jl\")\n",
    "include(\"setup.jl\")\n",
    "\n",
    "s = ArgParseSettings()\n",
    "@add_arg_table! s begin\n",
    "    \"--dataset\"\n",
    "        help = \"which environment to use\"\n",
    "        arg_type = String\n",
    "        default = \"halfcheetah-medium-expert-v2\"\n",
    "    \"--exp_name\"\n",
    "        help = \"name of the experiment\"\n",
    "        arg_type = String\n",
    "        default = \"debug\"\n",
    "    \"--seed\"\n",
    "        help = \"seed\"\n",
    "        default = 42\n",
    "    \"--beam_width\"\n",
    "        default = 64\n",
    "    \"--n_expand\"\n",
    "        default = 4\n",
    "    \"--suffix\"\n",
    "        default = \"\"\n",
    "    \"--config\"\n",
    "        help = \"relative jl file path with configurations\"\n",
    "        arg_type = String\n",
    "        default = \"../config/vqvae.jl\"\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "79ddbdba-d4ef-4823-ad70-27c3849ed399",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Any, Any} with 75 entries:\n",
       "  \"blocks.2.ln2.bias\"          => PyObject tensor([0., 0., 0., 0., 0., 0., 0., …\n",
       "  \"blocks.0.attn.value.bias\"   => PyObject tensor([0., 0., 0., 0., 0., 0., 0., …\n",
       "  \"state_emb.bias\"             => PyObject tensor([0., 0., 0., 0., 0., 0., 0., …\n",
       "  \"blocks.1.attn.proj.bias\"    => PyObject tensor([0., 0., 0., 0., 0., 0., 0., …\n",
       "  \"blocks.3.attn.value.bias\"   => PyObject tensor([0., 0., 0., 0., 0., 0., 0., …\n",
       "  \"blocks.0.ln2.bias\"          => PyObject tensor([0., 0., 0., 0., 0., 0., 0., …\n",
       "  \"blocks.0.mlp.0.bias\"        => PyObject tensor([0., 0., 0.,  ..., 0., 0., 0.…\n",
       "  \"blocks.3.ln1.weight\"        => PyObject tensor([1., 1., 1., 1., 1., 1., 1., …\n",
       "  \"pos_emb\"                    => PyObject tensor([[[0., 0., 0.,  ..., 0., 0., …\n",
       "  \"blocks.0.mlp.0.weight\"      => PyObject tensor([[ 0.0037,  0.0118, -0.0088, …\n",
       "  \"blocks.2.attn.query.bias\"   => PyObject tensor([0., 0., 0., 0., 0., 0., 0., …\n",
       "  \"blocks.3.attn.mask\"         => PyObject tensor([[[[1., 0., 0., 0., 0., 0., 0…\n",
       "  \"blocks.2.mlp.0.weight\"      => PyObject tensor([[ 0.0137,  0.0011,  0.0363, …\n",
       "  \"blocks.1.mlp.0.weight\"      => PyObject tensor([[-0.0377,  0.0069,  0.0151, …\n",
       "  \"blocks.3.mlp.2.weight\"      => PyObject tensor([[-0.0237, -0.0118,  0.0070, …\n",
       "  \"blocks.1.attn.value.weight\" => PyObject tensor([[ 0.0072, -0.0231,  0.0031, …\n",
       "  \"blocks.0.attn.query.weight\" => PyObject tensor([[-0.0095,  0.0189,  0.0020, …\n",
       "  \"blocks.2.attn.query.weight\" => PyObject tensor([[-0.0036, -0.0159,  0.0120, …\n",
       "  \"blocks.2.attn.key.weight\"   => PyObject tensor([[-0.0108, -0.0095, -0.0041, …\n",
       "  \"blocks.0.attn.mask\"         => PyObject tensor([[[[1., 0., 0., 0., 0., 0., 0…\n",
       "  \"blocks.1.ln2.bias\"          => PyObject tensor([0., 0., 0., 0., 0., 0., 0., …\n",
       "  \"blocks.3.ln2.bias\"          => PyObject tensor([0., 0., 0., 0., 0., 0., 0., …\n",
       "  \"blocks.2.mlp.0.bias\"        => PyObject tensor([0., 0., 0.,  ..., 0., 0., 0.…\n",
       "  \"blocks.1.mlp.2.weight\"      => PyObject tensor([[ 0.0030, -0.0203,  0.0300, …\n",
       "  \"head.weight\"                => PyObject tensor([[-0.0088,  0.0295,  0.0212, …\n",
       "  ⋮                            => ⋮"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@pyimport torch\n",
    "@pyimport numpy\n",
    "\n",
    "weights = torch.load(\"test/files/gpt_trained.pt\", map_location=torch.device(\"cpu\"))\n",
    "prior_weights = torch.load(\"test/files/prior_model.pt\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "702a6c07-4a9e-413b-8b28-f8e482835a3f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ utils/setup ] Reading config: ../config/vqvae.jl:hopper_medium_replay_v2\n",
      "/Users/mehmeteneserciyes/logs_julia/hopper-medium-replay-v2/T-1-42/ already exists. Proceeding...\n",
      "Made directory /Users/mehmeteneserciyes/logs_julia/hopper-medium-replay-v2/T-1-42/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"/Users/mehmeteneserciyes/logs_julia/hopper-medium-replay-v2/T-1-42\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#######################\n",
    "####### setup ########\n",
    "#######################\n",
    "\n",
    "super_args = Dict{String, Any}(\n",
    "    \"dataset\"=> \"hopper-medium-replay-v2\",\n",
    "    \"exp_name\"=> \"T-1-42\",\n",
    "    \"seed\"=> 42,\n",
    "    \"config\"=> \"../config/vqvae.jl\",\n",
    "    \"beam_width\"=>64,\n",
    "    \"n_expand\"=>4,\n",
    "    \"suffix\"=>\"\"\n",
    ")\n",
    "args = parser(super_args, experiment=\"plan\")\n",
    "\n",
    "args[\"logbase\"] = expanduser(args[\"logbase\"])\n",
    "args[\"savepath\"] = expanduser(args[\"savepath\"])\n",
    "args[\"loadpath\"] = joinpath(args[\"logbase\"], args[\"dataset\"], args[\"exp_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ebef0c4d-9e0f-4515-9998-4128aca974e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ datasets/sequence ] Sequence length: 25 | Step: 1 | Max path length: 1000\n",
      "[ datasets/sequence ] Loading...\n",
      "✓\n",
      "[ datasets/sequence ] Segmenting..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "load datafile: 100%|███████████████████████████| 11/11 [00:00<00:00, 14.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mCalculating values 100%|█████████████████████████████████| Time: 0:00:04\u001b[39m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SequenceDataset(PyObject <d4rl.utils.wrappers.NormalizedBoxEnv object at 0x157f17e80>, 25, 1, 1000, \"cuda:0\", false, true, true, Float32[1.2305137; -0.043713972; … ; -0.14465895; -0.19652691;;], Float32[0.17565039; 0.0636919; … ; 1.6540343; 5.1086063;;], Float32[0.09147097; 0.37909505; -0.00019374755;;], Float32[0.53679484; 0.5815471; 0.75734293;;], 2.372544f0, 1.0507907f0, Float32[0.110015035 0.10879681 … 0.5080938 0.40982184; 0.7504013 0.714008 … -0.77624345 -0.819888; … ; 0.08837258 0.08248433 … 0.39702943 0.17106935; 0.03892147 -0.22365776 … 0.033442777 0.035735335], Float32[-0.98633546 -1.2569964 … -1.3178613 0.85888374; -0.014222167 -0.42894647 … 1.0531265 1.052914; -1.2321614 -0.9727596 … 1.2837203 1.2837336], Float32[0.110015035 0.10879681 … 0.5080938 0.40982184; 0.7504013 0.714008 … -0.77624345 -0.819888; … ; -1.3354627 -1.3966663 … 0.21831672 0.22489393; -2.1312575 -2.1479235 … -1.3035873 -1.3279964], Float32[-1.3354627 -1.3966663 … 0.21831672 0.22489393], Bool[0, 0, 0, 0, 0, 0, 0, 0, 0, 0  …  0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0.110015035 0.10879681 … 0.0 0.0; 0.7504013 0.714008 … 0.0 0.0; … ; -1.3354627 -1.3966663 … 0.0 0.0; -2.1312575 -2.1479235 … 0.0 0.0;;; 0.11668911 0.115598485 … 0.0 0.0; 0.63302076 0.60572225 … 0.0 0.0; … ; -1.3638498 -1.3860055 … 0.0 0.0; -1.758586 -1.7715937 … 0.0 0.0;;; 0.12981127 0.12849872 … 0.0 0.0; 0.69134223 0.6510075 … 0.0 0.0; … ; -1.3158275 -1.3135796 … 0.0 0.0; -1.4027678 -1.4129004 … 0.0 0.0;;; … ;;; 0.12878375 0.12662354 … 0.0 0.0; 0.6539842 0.6428166 … 0.0 0.0; … ; -1.3149651 -1.2680231 … 0.0 0.0; 0.84898937 0.8611492 … 0.0 0.0;;; 0.09785049 0.09574863 … 0.0 0.0; 0.7383546 0.71809006 … 0.0 0.0; … ; -1.3309506 -1.2959023 … 0.0 0.0; 0.9166284 0.92974854 … 0.0 0.0;;; 0.10580997 0.10346448 … 0.0 0.0; 0.6577066 0.6587155 … 0.0 0.0; … ; -1.2977443 -1.281237 … 0.0 0.0; 0.20837517 0.21419555 … 0.0 0.0], Bool[0 0 … 0 0; 0 0 … 0 0; … ; 1 1 … 1 1; 1 1 … 1 1], [11, 33, 58, 12, 11, 19, 16, 42, 17, 25  …  358, 426, 189, 27, 437, 421, 142, 401, 455, 143], [-1.3354627 -1.3966663 … -2.2578657 -2.2578657;;; -1.3638498 -1.3860055 … -2.2578657 -2.2578657;;; -1.3158275 -1.3135796 … -2.2578657 -2.2578657;;; … ;;; -1.3149651 -1.2680231 … -2.2578657 -2.2578657;;; -1.3309506 -1.2959023 … -2.2578657 -2.2578657;;; -1.2977443 -1.281237 … -2.2578657 -2.2578657], 0.99, [1.0 0.99 … 4.404779860285468e-5 4.360732061682613e-5], [-2.1312575 -2.1479235 … -1.3279964 -1.3279964;;; -1.758586 -1.7715937 … -1.3279964 -1.3279964;;; -1.4027678 -1.4129004 … -1.3279964 -1.3279964;;; … ;;; 0.84898937 0.8611492 … -1.3279964 -1.3279964;;; 0.9166284 0.92974854 … -1.3279964 -1.3279964;;; 0.20837517 0.21419555 … -1.3279964 -1.3279964], Float32[-2.1312575 -2.1479235 … -1.3035873 -1.3279964], 141.9371f0, 106.88064f0, 1.0, 0.0, Any[(1, 1, 26), (1, 2, 27), (1, 3, 28), (1, 4, 29), (1, 5, 30), (1, 6, 31), (1, 7, 32), (1, 8, 33), (1, 9, 34), (1, 10, 35)  …  (2041, 133, 158), (2041, 134, 159), (2041, 135, 160), (2041, 136, 161), (2041, 137, 162), (2041, 138, 163), (2041, 139, 164), (2041, 140, 165), (2041, 141, 166), (2041, 142, 167)], Any[], 11, 3, 16, Array{Float32})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = load_environment(args[\"dataset\"])\n",
    "dataset_config = Knet.load(joinpath(args[\"loadpath\"] , \"dataset_config.jld2\"), \"config\")\n",
    "\n",
    "dataset = SequenceDataset(\n",
    "    dataset_config[\"env_name\"];\n",
    "    penalty=dataset_config[\"penalty\"],\n",
    "    sequence_length=dataset_config[\"sequence_length\"], \n",
    "    step=dataset_config[\"step\"], \n",
    "    discount=dataset_config[\"discount\"], \n",
    "    disable_goal=dataset_config[\"disable_goal\"], \n",
    "    normalize_raw=dataset_config[\"normalize_raw\"], \n",
    "    normalize_reward=dataset_config[\"normalize_reward\"],\n",
    "    max_path_length=dataset_config[\"max_path_length\"],\n",
    "    atype=dataset_config[\"atype\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948dca42-88ee-44dc-8fa6-53ddcef44d1c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Representation model init and weight loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f00895a8-6bb3-4ff4-9e71-4fe99faa9509",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedCollections.OrderedDict{String, Any} with 52 entries:\n",
       "  \"model\"                      => \"VQTransformer\"\n",
       "  \"tag\"                        => \"experiment\"\n",
       "  \"state_conditional\"          => true\n",
       "  \"N\"                          => 100\n",
       "  \"discount\"                   => 0.99\n",
       "  \"n_layer\"                    => 4\n",
       "  \"n_head\"                     => 4\n",
       "  \"n_epochs_ref\"               => 50\n",
       "  \"n_saves\"                    => 3\n",
       "  \"logbase\"                    => \"~/logs_julia/\"\n",
       "  \"device\"                     => \"cuda\"\n",
       "  \"K\"                          => 512\n",
       "  \"latent_step\"                => 3\n",
       "  \"n_embd\"                     => 512\n",
       "  \"trajectory_embd\"            => 512\n",
       "  \"batch_size\"                 => 512\n",
       "  \"learning_rate\"              => 0.0002\n",
       "  \"lr_decay\"                   => false\n",
       "  \"seed\"                       => 42\n",
       "  \"embd_pdrop\"                 => 0.0\n",
       "  \"resid_pdrop\"                => 0.0\n",
       "  \"attn_pdrop\"                 => 0.0\n",
       "  \"step\"                       => 1\n",
       "  \"subsampled_sequence_length\" => 25\n",
       "  \"termination_penalty\"        => -100\n",
       "  ⋮                            => ⋮"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_config = Knet.load(joinpath(\"/Users/mehmeteneserciyes/logs_julia/hopper-medium-replay-v2/T-1-42\", \"model_config.jld2\"), \"config\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f5010a8-4149-4928-a851-1582b90b21cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gpt = VQContinuousVAE(model_config);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e1b3ea2f-8bf2-4343-90af-cab9a7516f18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# encoder\n",
    "gpt.model.embed.w = Param(atype(weights[\"model.embed.weight\"][:cpu]()[:numpy]()))\n",
    "gpt.model.embed.b = Param(atype(weights[\"model.embed.bias\"][:cpu]()[:numpy]()))\n",
    "\n",
    "gpt.model.pos_emb = Param(atype(permutedims(weights[\"model.pos_emb\"][:cpu]()[:numpy](), (3,2,1))))\n",
    "\n",
    "for i in 1:model_config[\"n_layer\"]\n",
    "    gpt.model.encoder.layers[i].ln1.a = Param(atype(weights[\"model.encoder.$(i-1).ln1.weight\"][:cpu]()[:numpy]()))\n",
    "    gpt.model.encoder.layers[i].ln1.b = Param(atype(weights[\"model.encoder.$(i-1).ln1.bias\"][:cpu]()[:numpy]()))\n",
    "    gpt.model.encoder.layers[i].ln2.a = Param(atype(weights[\"model.encoder.$(i-1).ln2.weight\"][:cpu]()[:numpy]()))\n",
    "    gpt.model.encoder.layers[i].ln2.b = Param(atype(weights[\"model.encoder.$(i-1).ln2.bias\"][:cpu]()[:numpy]()))\n",
    "\n",
    "    gpt.model.encoder.layers[i].attn.key.w = Param(atype(weights[\"model.encoder.$(i-1).attn.key.weight\"][:cpu]()[:numpy]()))\n",
    "    gpt.model.encoder.layers[i].attn.key.b = Param(atype(weights[\"model.encoder.$(i-1).attn.key.bias\"][:cpu]()[:numpy]()))\n",
    "    gpt.model.encoder.layers[i].attn.query.w = Param(atype(weights[\"model.encoder.$(i-1).attn.query.weight\"][:cpu]()[:numpy]()))\n",
    "    gpt.model.encoder.layers[i].attn.query.b = Param(atype(weights[\"model.encoder.$(i-1).attn.query.bias\"][:cpu]()[:numpy]()))\n",
    "    gpt.model.encoder.layers[i].attn.value.w = Param(atype(weights[\"model.encoder.$(i-1).attn.value.weight\"][:cpu]()[:numpy]()))\n",
    "    gpt.model.encoder.layers[i].attn.value.b = Param(atype(weights[\"model.encoder.$(i-1).attn.value.bias\"][:cpu]()[:numpy]()))\n",
    "    gpt.model.encoder.layers[i].attn.proj.w = Param(atype(weights[\"model.encoder.$(i-1).attn.proj.weight\"][:cpu]()[:numpy]()))\n",
    "    gpt.model.encoder.layers[i].attn.proj.b = Param(atype(weights[\"model.encoder.$(i-1).attn.proj.bias\"][:cpu]()[:numpy]()))\n",
    "\n",
    "    gpt.model.encoder.layers[i].mlp.layers[1].w = Param(atype(weights[\"model.encoder.$(i-1).mlp.0.weight\"][:cpu]()[:numpy]()))\n",
    "    gpt.model.encoder.layers[i].mlp.layers[1].b = Param(atype(weights[\"model.encoder.$(i-1).mlp.0.bias\"][:cpu]()[:numpy]()))\n",
    "    gpt.model.encoder.layers[i].mlp.layers[3].w = Param(atype(weights[\"model.encoder.$(i-1).mlp.2.weight\"][:cpu]()[:numpy]()))\n",
    "    gpt.model.encoder.layers[i].mlp.layers[3].b = Param(atype(weights[\"model.encoder.$(i-1).mlp.2.bias\"][:cpu]()[:numpy]()))\n",
    "end\n",
    "\n",
    "gpt.model.cast_embed.w = Param(atype(weights[\"model.cast_embed.weight\"][:cpu]()[:numpy]()))\n",
    "gpt.model.cast_embed.b = Param(atype(weights[\"model.cast_embed.bias\"][:cpu]()[:numpy]()))\n",
    "\n",
    "# Decoder\n",
    "gpt.model.latent_mixing.w = Param(atype(weights[\"model.latent_mixing.weight\"][:cpu]()[:numpy]()))\n",
    "gpt.model.latent_mixing.b = Param(atype(weights[\"model.latent_mixing.bias\"][:cpu]()[:numpy]()))\n",
    "\n",
    "for i in 1:model_config[\"n_layer\"]\n",
    "    gpt.model.decoder.layers[i].ln1.a = Param(atype(weights[\"model.decoder.$(i-1).ln1.weight\"][:cpu]()[:numpy]()))\n",
    "    gpt.model.decoder.layers[i].ln1.b = Param(atype(weights[\"model.decoder.$(i-1).ln1.bias\"][:cpu]()[:numpy]()))\n",
    "    gpt.model.decoder.layers[i].ln2.a = Param(atype(weights[\"model.decoder.$(i-1).ln2.weight\"][:cpu]()[:numpy]()))\n",
    "    gpt.model.decoder.layers[i].ln2.b = Param(atype(weights[\"model.decoder.$(i-1).ln2.bias\"][:cpu]()[:numpy]()))\n",
    "\n",
    "    gpt.model.decoder.layers[i].attn.key.w = Param(atype(weights[\"model.decoder.$(i-1).attn.key.weight\"][:cpu]()[:numpy]()))\n",
    "    gpt.model.decoder.layers[i].attn.key.b = Param(atype(weights[\"model.decoder.$(i-1).attn.key.bias\"][:cpu]()[:numpy]()))\n",
    "    gpt.model.decoder.layers[i].attn.query.w = Param(atype(weights[\"model.decoder.$(i-1).attn.query.weight\"][:cpu]()[:numpy]()))\n",
    "    gpt.model.decoder.layers[i].attn.query.b = Param(atype(weights[\"model.decoder.$(i-1).attn.query.bias\"][:cpu]()[:numpy]()))\n",
    "    gpt.model.decoder.layers[i].attn.value.w = Param(atype(weights[\"model.decoder.$(i-1).attn.value.weight\"][:cpu]()[:numpy]()))\n",
    "    gpt.model.decoder.layers[i].attn.value.b = Param(atype(weights[\"model.decoder.$(i-1).attn.value.bias\"][:cpu]()[:numpy]()))\n",
    "    gpt.model.decoder.layers[i].attn.proj.w = Param(atype(weights[\"model.decoder.$(i-1).attn.proj.weight\"][:cpu]()[:numpy]()))\n",
    "    gpt.model.decoder.layers[i].attn.proj.b = Param(atype(weights[\"model.decoder.$(i-1).attn.proj.bias\"][:cpu]()[:numpy]()))\n",
    "\n",
    "    gpt.model.decoder.layers[i].mlp.layers[1].w = Param(atype(weights[\"model.decoder.$(i-1).mlp.0.weight\"][:cpu]()[:numpy]()))\n",
    "    gpt.model.decoder.layers[i].mlp.layers[1].b = Param(atype(weights[\"model.decoder.$(i-1).mlp.0.bias\"][:cpu]()[:numpy]()))\n",
    "    gpt.model.decoder.layers[i].mlp.layers[3].w = Param(atype(weights[\"model.decoder.$(i-1).mlp.2.weight\"][:cpu]()[:numpy]()))\n",
    "    gpt.model.decoder.layers[i].mlp.layers[3].b = Param(atype(weights[\"model.decoder.$(i-1).mlp.2.bias\"][:cpu]()[:numpy]()))\n",
    "end\n",
    "\n",
    "gpt.model.ln_f.a = Param(atype(weights[\"model.ln_f.weight\"][:cpu]()[:numpy]()))\n",
    "gpt.model.ln_f.b = Param(atype(weights[\"model.ln_f.bias\"][:cpu]()[:numpy]()))\n",
    "\n",
    "gpt.model.predict.w = Param(atype(weights[\"model.predict.weight\"][:cpu]()[:numpy]()))\n",
    "gpt.model.predict.b = Param(atype(weights[\"model.predict.bias\"][:cpu]()[:numpy]()))\n",
    "\n",
    "# codebook\n",
    "gpt.model.codebook.embedding = Param(atype(weights[\"model.codebook.embedding\"][:cpu]()[:numpy]()'))\n",
    "gpt.model.codebook.ema_count = Param(atype(weights[\"model.codebook.ema_count\"][:cpu]()[:numpy]()))\n",
    "gpt.model.codebook.ema_w = Param(atype(weights[\"model.codebook.ema_w\"][:cpu]()[:numpy]()'))\n",
    "\n",
    "# padding vector\n",
    "gpt.padding_vector = atype(normalize_joined_single(dataset, atype(zeros(gpt.transition_dim-1))));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f93455-c04b-46de-b8b1-62cd77cff421",
   "metadata": {
    "tags": []
   },
   "source": [
    "# TransformerPrior Init and Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1a84589a-35c6-41f4-b85d-624c491921d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ utils/setup ] Reading config: ../config/vqvae.jl:hopper_medium_replay_v2\n",
      "/Users/mehmeteneserciyes/logs_julia/hopper-medium-replay-v2/T-1-42/ already exists. Proceeding...\n",
      "Made directory /Users/mehmeteneserciyes/logs_julia/hopper-medium-replay-v2/T-1-42/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = parser(super_args, experiment=\"train\")\n",
    "args[\"logbase\"] = expanduser(args[\"logbase\"])\n",
    "args[\"savepath\"] = expanduser(args[\"savepath\"])\n",
    "args[\"savepath\"] = \"/Users/mehmeteneserciyes/logs_julia/hopper-medium-replay-v2/T-1-42/\"\n",
    "block_size = args[\"subsampled_sequence_length\"] ÷ args[\"latent_step\"]\n",
    "obs_dim = dataset.observation_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6d8b3295-0841-470a-a435-82cc90b60d38",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_config = deepcopy(args)\n",
    "model_config[\"block_size\"] = block_size\n",
    "model_config[\"observation_dim\"] = obs_dim\n",
    "model_config[\"n_embd\"] = args[\"n_embd\"] * args[\"n_head\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3f8e6975-9f21-4d31-8277-e6a426bd278b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0f0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# turn off dropout\n",
    "model_config[\"embd_pdrop\"] = 0.0f0\n",
    "model_config[\"attn_pdrop\"] = 0.0f0\n",
    "model_config[\"resid_pdrop\"] = 0.0f0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ae486b8a-8a46-47c6-94fe-5f33039f6283",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prior = TransformerPrior(model_config);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "413a9612-295f-4d83-a5b4-34db1b432001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder\n",
    "prior.tok_emb = Param(atype(prior_weights[\"tok_emb.weight\"][:cpu]()[:numpy]()'))\n",
    "prior.pos_emb = Param(atype(permutedims(prior_weights[\"pos_emb\"][:cpu]()[:numpy](), (3,2,1))))\n",
    "\n",
    "prior.state_emb.w = Param(atype(prior_weights[\"state_emb.weight\"][:cpu]()[:numpy]()))\n",
    "prior.state_emb.b = Param(atype(prior_weights[\"state_emb.bias\"][:cpu]()[:numpy]()))\n",
    "\n",
    "for i in 1:model_config[\"n_layer\"]\n",
    "    prior.blocks.layers[i].ln1.a = Param(atype(prior_weights[\"blocks.$(i-1).ln1.weight\"][:cpu]()[:numpy]()))\n",
    "    prior.blocks.layers[i].ln1.b = Param(atype(prior_weights[\"blocks.$(i-1).ln1.bias\"][:cpu]()[:numpy]()))\n",
    "    prior.blocks.layers[i].ln2.a = Param(atype(prior_weights[\"blocks.$(i-1).ln2.weight\"][:cpu]()[:numpy]()))\n",
    "    prior.blocks.layers[i].ln2.b = Param(atype(prior_weights[\"blocks.$(i-1).ln2.bias\"][:cpu]()[:numpy]()))\n",
    "\n",
    "    prior.blocks.layers[i].attn.key.w = Param(atype(prior_weights[\"blocks.$(i-1).attn.key.weight\"][:cpu]()[:numpy]()))\n",
    "    prior.blocks.layers[i].attn.key.b = Param(atype(prior_weights[\"blocks.$(i-1).attn.key.bias\"][:cpu]()[:numpy]()))\n",
    "    prior.blocks.layers[i].attn.query.w = Param(atype(prior_weights[\"blocks.$(i-1).attn.query.weight\"][:cpu]()[:numpy]()))\n",
    "    prior.blocks.layers[i].attn.query.b = Param(atype(prior_weights[\"blocks.$(i-1).attn.query.bias\"][:cpu]()[:numpy]()))\n",
    "    prior.blocks.layers[i].attn.value.w = Param(atype(prior_weights[\"blocks.$(i-1).attn.value.weight\"][:cpu]()[:numpy]()))\n",
    "    prior.blocks.layers[i].attn.value.b = Param(atype(prior_weights[\"blocks.$(i-1).attn.value.bias\"][:cpu]()[:numpy]()))\n",
    "    prior.blocks.layers[i].attn.proj.w = Param(atype(prior_weights[\"blocks.$(i-1).attn.proj.weight\"][:cpu]()[:numpy]()))\n",
    "    prior.blocks.layers[i].attn.proj.b = Param(atype(prior_weights[\"blocks.$(i-1).attn.proj.bias\"][:cpu]()[:numpy]()))\n",
    "\n",
    "    prior.blocks.layers[i].mlp.layers[1].w = Param(atype(prior_weights[\"blocks.$(i-1).mlp.0.weight\"][:cpu]()[:numpy]()))\n",
    "    prior.blocks.layers[i].mlp.layers[1].b = Param(atype(prior_weights[\"blocks.$(i-1).mlp.0.bias\"][:cpu]()[:numpy]()))\n",
    "    prior.blocks.layers[i].mlp.layers[3].w = Param(atype(prior_weights[\"blocks.$(i-1).mlp.2.weight\"][:cpu]()[:numpy]()))\n",
    "    prior.blocks.layers[i].mlp.layers[3].b = Param(atype(prior_weights[\"blocks.$(i-1).mlp.2.bias\"][:cpu]()[:numpy]()))\n",
    "end\n",
    "\n",
    "prior.ln_f.a = Param(atype(prior_weights[\"ln_f.weight\"][:cpu]()[:numpy]()))\n",
    "prior.ln_f.b = Param(atype(prior_weights[\"ln_f.bias\"][:cpu]()[:numpy]()))\n",
    "# no bias\n",
    "prior.head.w = Param(atype(prior_weights[\"head.weight\"][:cpu]()[:numpy]())); "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43657dc4-82d5-4ecb-a8ba-ffc754028cf8",
   "metadata": {},
   "source": [
    "# Planning part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "735424ee-dd80-4de3-9ed6-e259c7499ef2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discount = dataset.discount\n",
    "observation_dim = dataset.observation_dim\n",
    "action_dim = dataset.action_dim\n",
    "\n",
    "#######################\n",
    "###### main loop ######\n",
    "#######################\n",
    "REWARD_DIM = VALUE_DIM = 1\n",
    "transition_dim = observation_dim + action_dim + REWARD_DIM + VALUE_DIM\n",
    "\n",
    "observation = env.reset()\n",
    "total_reward = 0\n",
    "discount_return = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "df7beda0-60a1-40df-885f-a1a97239b357",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11-element Vector{Float64}:\n",
       "  1.253712370089423\n",
       " -0.00038758963847066895\n",
       " -0.004536975813829556\n",
       "  0.00418929445076901\n",
       " -0.002651174948780496\n",
       " -0.0006299949827345885\n",
       "  0.0032714934892716318\n",
       "  0.0007910854975872561\n",
       " -0.003877485202099127\n",
       "  0.0045930625544841645\n",
       "  0.00020891531807665565"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c440017-ab56-4c7a-9a3c-241e0c8081da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.5",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
