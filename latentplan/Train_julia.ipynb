{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "415483f6-6d12-4cba-9362-bb8f0f7500ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `~/Projects/latentplan.jl`\n"
     ]
    }
   ],
   "source": [
    "import Pkg\n",
    "Pkg.activate(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ffd3d5e-474a-4260-9369-c23281c32d6a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array{Float32}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Test\n",
    "using PyCall\n",
    "using Knet\n",
    "using Debugger: @enter, @bp, @run\n",
    "using CUDA\n",
    "\n",
    "if CUDA.functional()\n",
    "\tatype=KnetArray{Float32}\n",
    "else\t\n",
    "\tatype=Array{Float32}\n",
    "end\n",
    "cputype=Array{Float32}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "baa5c741-c8f4-4574-ad85-4d2aea70b9f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: replacing module VQVAEConfig.\n"
     ]
    }
   ],
   "source": [
    "include(\"datasets/sequence.jl\")\n",
    "include(\"models/common.jl\")\n",
    "include(\"models/transformers.jl\")\n",
    "include(\"models/vqvae.jl\")\n",
    "include(\"setup.jl\")\n",
    "\n",
    "@pyimport torch\n",
    "\n",
    "weights = torch.load(\"test/files/gpt_weights_hopper.pt\")\n",
    "\n",
    "@pyimport numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4137adb-e566-41cc-90df-cbbf409132ad",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8394bac5-1dd2-4748-b937-9c5b23f71252",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ utils/setup ] Reading config: ../config/vqvae.jl:hopper_medium_replay_v2\n",
      "/Users/mehmeteneserciyes/logs_julia/hopper-medium-replay-v2/debug/ already exists. Proceeding...\n",
      "Made directory /Users/mehmeteneserciyes/logs_julia/hopper-medium-replay-v2/debug/\n"
     ]
    }
   ],
   "source": [
    "super_args = Dict{String, Any}(\n",
    "    \"dataset\"=> \"hopper-medium-replay-v2\",\n",
    "    \"exp_name\"=> \"debug\",\n",
    "    \"seed\"=> 42,\n",
    "    \"config\"=> \"../config/vqvae.jl\",\n",
    ")\n",
    "\n",
    "args = parser(super_args, experiment=\"train\")\n",
    "\n",
    "config = deepcopy(args)\n",
    "config[\"block_size\"] = 425\n",
    "config[\"observation_dim\"] = 11\n",
    "config[\"action_dim\"] = 3\n",
    "config[\"transition_dim\"] = 17\n",
    "config[\"n_embd\"] = args[\"n_embd\"] * args[\"n_head\"]\n",
    "config[\"vocab_size\"] = args[\"N\"]\n",
    "\n",
    "vq_model = VQContinuousVAE(config);\n",
    "vq_model.padding_vector = atype(normalize_joined_single(dataset, atype(zeros(vq_model.transition_dim-1))));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "067a50ac-1252-4012-9f6f-2e276d274c4d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reset_codebook (generic function with 1 method)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function reset_codebook()\n",
    "    vq_model.model.codebook.embedding = Param(atype(weights[\"model.codebook.embedding\"][:cpu]()[:numpy]()'))\n",
    "    vq_model.model.codebook.ema_count = Param(atype(weights[\"model.codebook.ema_count\"][:cpu]()[:numpy]()))\n",
    "    vq_model.model.codebook.ema_w = Param(atype(weights[\"model.codebook.ema_w\"][:cpu]()[:numpy]()'))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a952b7df-e058-4454-9569-6a600a40c76e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Load weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9374c0e1-f832-4949-9cff-2f472d16368d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# encoder\n",
    "vq_model.model.embed.w = Param(atype(weights[\"model.embed.weight\"][:cpu]()[:numpy]()))\n",
    "vq_model.model.embed.b = Param(atype(weights[\"model.embed.bias\"][:cpu]()[:numpy]()))\n",
    "\n",
    "vq_model.model.pos_emb = Param(atype(permutedims(weights[\"model.pos_emb\"][:cpu]()[:numpy](), (3,2,1))))\n",
    "\n",
    "for i in 1:config[\"n_layer\"]\n",
    "    vq_model.model.encoder.layers[i].ln1.a = Param(atype(weights[\"model.encoder.$(i-1).ln1.weight\"][:cpu]()[:numpy]()))\n",
    "    vq_model.model.encoder.layers[i].ln1.b = Param(atype(weights[\"model.encoder.$(i-1).ln1.bias\"][:cpu]()[:numpy]()))\n",
    "    vq_model.model.encoder.layers[i].ln2.a = Param(atype(weights[\"model.encoder.$(i-1).ln2.weight\"][:cpu]()[:numpy]()))\n",
    "    vq_model.model.encoder.layers[i].ln2.b = Param(atype(weights[\"model.encoder.$(i-1).ln2.bias\"][:cpu]()[:numpy]()))\n",
    "\n",
    "    vq_model.model.encoder.layers[i].attn.key.w = Param(atype(weights[\"model.encoder.$(i-1).attn.key.weight\"][:cpu]()[:numpy]()))\n",
    "    vq_model.model.encoder.layers[i].attn.key.b = Param(atype(weights[\"model.encoder.$(i-1).attn.key.bias\"][:cpu]()[:numpy]()))\n",
    "    vq_model.model.encoder.layers[i].attn.query.w = Param(atype(weights[\"model.encoder.$(i-1).attn.query.weight\"][:cpu]()[:numpy]()))\n",
    "    vq_model.model.encoder.layers[i].attn.query.b = Param(atype(weights[\"model.encoder.$(i-1).attn.query.bias\"][:cpu]()[:numpy]()))\n",
    "    vq_model.model.encoder.layers[i].attn.value.w = Param(atype(weights[\"model.encoder.$(i-1).attn.value.weight\"][:cpu]()[:numpy]()))\n",
    "    vq_model.model.encoder.layers[i].attn.value.b = Param(atype(weights[\"model.encoder.$(i-1).attn.value.bias\"][:cpu]()[:numpy]()))\n",
    "    vq_model.model.encoder.layers[i].attn.proj.w = Param(atype(weights[\"model.encoder.$(i-1).attn.proj.weight\"][:cpu]()[:numpy]()))\n",
    "    vq_model.model.encoder.layers[i].attn.proj.b = Param(atype(weights[\"model.encoder.$(i-1).attn.proj.bias\"][:cpu]()[:numpy]()))\n",
    "\n",
    "    vq_model.model.encoder.layers[i].mlp.layers[1].w = Param(atype(weights[\"model.encoder.$(i-1).mlp.0.weight\"][:cpu]()[:numpy]()))\n",
    "    vq_model.model.encoder.layers[i].mlp.layers[1].b = Param(atype(weights[\"model.encoder.$(i-1).mlp.0.bias\"][:cpu]()[:numpy]()))\n",
    "    vq_model.model.encoder.layers[i].mlp.layers[3].w = Param(atype(weights[\"model.encoder.$(i-1).mlp.2.weight\"][:cpu]()[:numpy]()))\n",
    "    vq_model.model.encoder.layers[i].mlp.layers[3].b = Param(atype(weights[\"model.encoder.$(i-1).mlp.2.bias\"][:cpu]()[:numpy]()))\n",
    "end\n",
    "\n",
    "vq_model.model.cast_embed.w = Param(atype(weights[\"model.cast_embed.weight\"][:cpu]()[:numpy]()))\n",
    "vq_model.model.cast_embed.b = Param(atype(weights[\"model.cast_embed.bias\"][:cpu]()[:numpy]()))\n",
    "\n",
    "# Decoder\n",
    "vq_model.model.latent_mixing.w = Param(atype(weights[\"model.latent_mixing.weight\"][:cpu]()[:numpy]()))\n",
    "vq_model.model.latent_mixing.b = Param(atype(weights[\"model.latent_mixing.bias\"][:cpu]()[:numpy]()))\n",
    "\n",
    "for i in 1:config[\"n_layer\"]\n",
    "    vq_model.model.decoder.layers[i].ln1.a = Param(atype(weights[\"model.decoder.$(i-1).ln1.weight\"][:cpu]()[:numpy]()))\n",
    "    vq_model.model.decoder.layers[i].ln1.b = Param(atype(weights[\"model.decoder.$(i-1).ln1.bias\"][:cpu]()[:numpy]()))\n",
    "    vq_model.model.decoder.layers[i].ln2.a = Param(atype(weights[\"model.decoder.$(i-1).ln2.weight\"][:cpu]()[:numpy]()))\n",
    "    vq_model.model.decoder.layers[i].ln2.b = Param(atype(weights[\"model.decoder.$(i-1).ln2.bias\"][:cpu]()[:numpy]()))\n",
    "\n",
    "    vq_model.model.decoder.layers[i].attn.key.w = Param(atype(weights[\"model.decoder.$(i-1).attn.key.weight\"][:cpu]()[:numpy]()))\n",
    "    vq_model.model.decoder.layers[i].attn.key.b = Param(atype(weights[\"model.decoder.$(i-1).attn.key.bias\"][:cpu]()[:numpy]()))\n",
    "    vq_model.model.decoder.layers[i].attn.query.w = Param(atype(weights[\"model.decoder.$(i-1).attn.query.weight\"][:cpu]()[:numpy]()))\n",
    "    vq_model.model.decoder.layers[i].attn.query.b = Param(atype(weights[\"model.decoder.$(i-1).attn.query.bias\"][:cpu]()[:numpy]()))\n",
    "    vq_model.model.decoder.layers[i].attn.value.w = Param(atype(weights[\"model.decoder.$(i-1).attn.value.weight\"][:cpu]()[:numpy]()))\n",
    "    vq_model.model.decoder.layers[i].attn.value.b = Param(atype(weights[\"model.decoder.$(i-1).attn.value.bias\"][:cpu]()[:numpy]()))\n",
    "    vq_model.model.decoder.layers[i].attn.proj.w = Param(atype(weights[\"model.decoder.$(i-1).attn.proj.weight\"][:cpu]()[:numpy]()))\n",
    "    vq_model.model.decoder.layers[i].attn.proj.b = Param(atype(weights[\"model.decoder.$(i-1).attn.proj.bias\"][:cpu]()[:numpy]()))\n",
    "\n",
    "    vq_model.model.decoder.layers[i].mlp.layers[1].w = Param(atype(weights[\"model.decoder.$(i-1).mlp.0.weight\"][:cpu]()[:numpy]()))\n",
    "    vq_model.model.decoder.layers[i].mlp.layers[1].b = Param(atype(weights[\"model.decoder.$(i-1).mlp.0.bias\"][:cpu]()[:numpy]()))\n",
    "    vq_model.model.decoder.layers[i].mlp.layers[3].w = Param(atype(weights[\"model.decoder.$(i-1).mlp.2.weight\"][:cpu]()[:numpy]()))\n",
    "    vq_model.model.decoder.layers[i].mlp.layers[3].b = Param(atype(weights[\"model.decoder.$(i-1).mlp.2.bias\"][:cpu]()[:numpy]()))\n",
    "end\n",
    "\n",
    "vq_model.model.ln_f.a = Param(atype(weights[\"model.ln_f.weight\"][:cpu]()[:numpy]()))\n",
    "vq_model.model.ln_f.b = Param(atype(weights[\"model.ln_f.bias\"][:cpu]()[:numpy]()))\n",
    "\n",
    "vq_model.model.predict.w = Param(atype(weights[\"model.predict.weight\"][:cpu]()[:numpy]()))\n",
    "vq_model.model.predict.b = Param(atype(weights[\"model.predict.bias\"][:cpu]()[:numpy]()))\n",
    "\n",
    "# codebook\n",
    "vq_model.model.codebook.embedding = Param(atype(weights[\"model.codebook.embedding\"][:cpu]()[:numpy]()'))\n",
    "vq_model.model.codebook.ema_count = Param(atype(weights[\"model.codebook.ema_count\"][:cpu]()[:numpy]()))\n",
    "vq_model.model.codebook.ema_w = Param(atype(weights[\"model.codebook.ema_w\"][:cpu]()[:numpy]()'))\n",
    "\n",
    "# padding vector\n",
    "vq_model.padding_vector = atype(normalize_joined_single(dataset, atype(zeros(vq_model.transition_dim-1))));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361f0d9f-741a-472a-8790-b6cfb3491c4b",
   "metadata": {},
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9c442b11-b859-45b2-8477-729e2493b4e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset..\n",
      "[ datasets/sequence ] Sequence length: 25 | Step: 1 | Max path length: 1000\n",
      "[ datasets/sequence ] Loading...\n",
      "✓\n",
      "[ datasets/sequence ] Segmenting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "load datafile: 100%|███████████████████████████| 11/11 [00:00<00:00, 13.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mCalculating values 100%|█████████████████████████████████| Time: 0:00:05\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup done..\n"
     ]
    }
   ],
   "source": [
    "env_name = occursin(\"-v\", args[\"dataset\"]) ? args[\"dataset\"] : args[\"dataset\"] * \"-v0\"\n",
    "\n",
    "# env params\n",
    "sequence_length = args[\"subsampled_sequence_length\"] * args[\"step\"]\n",
    "args[\"logbase\"] = expanduser(args[\"logbase\"])\n",
    "args[\"savepath\"] = expanduser(args[\"savepath\"])\n",
    "if !isdir(args[\"savepath\"])\n",
    "    mkpath(args[\"savepath\"])\n",
    "end\n",
    "\n",
    "println(\"Loading dataset..\")\n",
    "\n",
    "dataset = SequenceDataset(\n",
    "    env_name;\n",
    "    penalty=args[\"termination_penalty\"], \n",
    "    sequence_length=sequence_length, \n",
    "    step=args[\"step\"], \n",
    "    discount=args[\"discount\"], \n",
    "    disable_goal=args[\"disable_goal\"], \n",
    "    normalize_raw=args[\"normalize\"], \n",
    "    normalize_reward=args[\"normalize_reward\"],\n",
    "    max_path_length=args[\"max_path_length\"],\n",
    "    atype=atype\n",
    ")\n",
    "\n",
    "println(\"Setup done..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c55ec89a-05b1-42be-81e8-5b70afa33fa4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loader = DataLoader(dataset; shuffle=false, batch_size=args[\"batch_size\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "17978a36-2eaf-4568-bcd7-6224019a99e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "opt_decay = AdamW(lr=args[\"learning_rate\"], beta1=0.9, beta2=0.95, weight_decay=0.1, gclip=1.0)\n",
    "opt_no_decay = AdamW(lr=args[\"learning_rate\"], beta1=0.9, beta2=0.95, weight_decay=0.0, gclip=1.0)\n",
    "for p in paramlist_decay(vq_model)\n",
    "    p.opt = clone(opt_decay)\n",
    "end\n",
    "for p in paramlist_no_decay(vq_model)\n",
    "    p.opt = clone(opt_no_decay)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9aaccf9e-f933-4165-8a5a-a9afa3afa6ec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "losssum (generic function with 1 method)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function zerograd_embedding(model::VQContinuousVAE)\n",
    "    model.model.codebook.embedding = value(model.model.codebook.embedding)\n",
    "    model.model.codebook.ema_count = value(model.model.codebook.ema_count)\n",
    "    model.model.codebook.ema_w = value(model.model.codebook.ema_w)\n",
    "end\n",
    "losssum(prediction) = mean(prediction[2] + prediction[3] + prediction[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "84d6d9d8-03f8-42cd-8f64-f3646d1055e0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss1: 22.369543\n",
      "Loss2: 22.044884\n",
      "Loss3: 22.045149\n",
      "Loss4: 22.791351\n",
      "Loss5: 22.968828\n",
      "Loss6: 18.977854\n",
      "Loss7: 14.574955\n",
      "Loss8: 13.411827\n",
      "Loss9: 13.778966\n",
      "Loss10: 9.11558\n",
      "Loss11: 7.1508503\n",
      "Loss12: 6.0912333\n",
      "Loss13: 8.363685\n",
      "Loss14: 12.680482\n",
      "Loss15: 14.417554\n",
      "Loss16: 20.291061\n",
      "Loss17: 18.609686\n",
      "Loss18: 20.447655\n",
      "Loss19: 17.55527\n",
      "Loss20: 9.726214\n"
     ]
    }
   ],
   "source": [
    "batch = nothing\n",
    "start_it = 1\n",
    "end_it = 20\n",
    "for (it, batch) in enumerate(loader)\n",
    "    if it<start_it\n",
    "        continue\n",
    "    elseif it>end_it\n",
    "        break\n",
    "    end\n",
    "    loss = @diff losssum(vq_model(batch...));\n",
    "    println(\"Loss\", it, \": \", value(loss))\n",
    "    for p in paramlist(vq_model)\n",
    "        update!(p, grad(loss, p))\n",
    "    end\n",
    "    zerograd_embedding(vq_model)\n",
    "    GC.gc(true)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ff3b2f-457a-4642-b39c-22ce790e6df8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.2",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
