{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8127f5d4-ca6d-46ac-8d5b-8071b22fc73a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `~/Projects/latentplan.jl`\n"
     ]
    }
   ],
   "source": [
    "import Pkg\n",
    "Pkg.activate(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b85f62c-5524-4d46-97d4-ea3f849e4920",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array{Float32}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Test\n",
    "using PyCall\n",
    "using Knet\n",
    "using Debugger: @enter, @bp, @run\n",
    "using CUDA\n",
    "\n",
    "if CUDA.functional()\n",
    "\tatype=KnetArray{Float32}\n",
    "else\t\n",
    "\tatype=Array{Float32}\n",
    "end\n",
    "cputype=Array{Float32}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27baf993-91d7-4a46-a74c-4b4ed3556f30",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Any, Any} with 75 entries:\n",
       "  \"blocks.2.ln2.bias\"          => PyObject tensor([0., 0., 0., 0., 0., 0., 0., …\n",
       "  \"blocks.0.attn.value.bias\"   => PyObject tensor([0., 0., 0., 0., 0., 0., 0., …\n",
       "  \"state_emb.bias\"             => PyObject tensor([0., 0., 0., 0., 0., 0., 0., …\n",
       "  \"blocks.1.attn.proj.bias\"    => PyObject tensor([0., 0., 0., 0., 0., 0., 0., …\n",
       "  \"blocks.3.attn.value.bias\"   => PyObject tensor([0., 0., 0., 0., 0., 0., 0., …\n",
       "  \"blocks.0.ln2.bias\"          => PyObject tensor([0., 0., 0., 0., 0., 0., 0., …\n",
       "  \"blocks.0.mlp.0.bias\"        => PyObject tensor([0., 0., 0.,  ..., 0., 0., 0.…\n",
       "  \"blocks.3.ln1.weight\"        => PyObject tensor([1., 1., 1., 1., 1., 1., 1., …\n",
       "  \"pos_emb\"                    => PyObject tensor([[[0., 0., 0.,  ..., 0., 0., …\n",
       "  \"blocks.0.mlp.0.weight\"      => PyObject tensor([[ 0.0037,  0.0118, -0.0088, …\n",
       "  \"blocks.2.attn.query.bias\"   => PyObject tensor([0., 0., 0., 0., 0., 0., 0., …\n",
       "  \"blocks.3.attn.mask\"         => PyObject tensor([[[[1., 0., 0., 0., 0., 0., 0…\n",
       "  \"blocks.2.mlp.0.weight\"      => PyObject tensor([[ 0.0137,  0.0011,  0.0363, …\n",
       "  \"blocks.1.mlp.0.weight\"      => PyObject tensor([[-0.0377,  0.0069,  0.0151, …\n",
       "  \"blocks.3.mlp.2.weight\"      => PyObject tensor([[-0.0237, -0.0118,  0.0070, …\n",
       "  \"blocks.1.attn.value.weight\" => PyObject tensor([[ 0.0072, -0.0231,  0.0031, …\n",
       "  \"blocks.0.attn.query.weight\" => PyObject tensor([[-0.0095,  0.0189,  0.0020, …\n",
       "  \"blocks.2.attn.query.weight\" => PyObject tensor([[-0.0036, -0.0159,  0.0120, …\n",
       "  \"blocks.2.attn.key.weight\"   => PyObject tensor([[-0.0108, -0.0095, -0.0041, …\n",
       "  \"blocks.0.attn.mask\"         => PyObject tensor([[[[1., 0., 0., 0., 0., 0., 0…\n",
       "  \"blocks.1.ln2.bias\"          => PyObject tensor([0., 0., 0., 0., 0., 0., 0., …\n",
       "  \"blocks.3.ln2.bias\"          => PyObject tensor([0., 0., 0., 0., 0., 0., 0., …\n",
       "  \"blocks.2.mlp.0.bias\"        => PyObject tensor([0., 0., 0.,  ..., 0., 0., 0.…\n",
       "  \"blocks.1.mlp.2.weight\"      => PyObject tensor([[ 0.0030, -0.0203,  0.0300, …\n",
       "  \"head.weight\"                => PyObject tensor([[-0.0088,  0.0295,  0.0212, …\n",
       "  ⋮                            => ⋮"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@pyimport torch\n",
    "@pyimport numpy\n",
    "\n",
    "weights = torch.load(\"test/files/gpt_trained.pt\", map_location=torch.device(\"cpu\"))\n",
    "prior_weights = torch.load(\"test/files/prior_model.pt\", map_location=torch.device(\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "64e68016-b439-468e-8ba1-92e3a88f77a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blocks.2.ln2.bias\n",
      "blocks.0.attn.value.bias\n",
      "state_emb.bias\n",
      "blocks.1.attn.proj.bias\n",
      "blocks.3.attn.value.bias\n",
      "blocks.0.ln2.bias\n",
      "blocks.0.mlp.0.bias\n",
      "blocks.3.ln1.weight\n",
      "pos_emb\n",
      "blocks.0.mlp.0.weight\n",
      "blocks.2.attn.query.bias\n",
      "blocks.3.attn.mask\n",
      "blocks.2.mlp.0.weight\n",
      "blocks.1.mlp.0.weight\n",
      "blocks.3.mlp.2.weight\n",
      "blocks.1.attn.value.weight\n",
      "blocks.0.attn.query.weight\n",
      "blocks.2.attn.query.weight\n",
      "blocks.2.attn.key.weight\n",
      "blocks.0.attn.mask\n",
      "blocks.1.ln2.bias\n",
      "blocks.3.ln2.bias\n",
      "blocks.2.mlp.0.bias\n",
      "blocks.1.mlp.2.weight\n",
      "head.weight\n",
      "blocks.2.ln2.weight\n",
      "blocks.2.attn.key.bias\n",
      "state_emb.weight\n",
      "blocks.3.ln2.weight\n",
      "blocks.1.attn.value.bias\n",
      "blocks.2.mlp.2.weight\n",
      "blocks.0.mlp.2.bias\n",
      "blocks.0.ln1.weight\n",
      "blocks.2.attn.proj.bias\n",
      "blocks.3.mlp.0.bias\n",
      "blocks.3.attn.key.weight\n",
      "blocks.1.attn.query.weight\n",
      "blocks.0.attn.value.weight\n",
      "blocks.1.ln2.weight\n",
      "blocks.1.attn.mask\n",
      "blocks.1.attn.query.bias\n",
      "blocks.0.ln1.bias\n",
      "blocks.3.attn.query.weight\n",
      "blocks.3.ln1.bias\n",
      "blocks.3.attn.proj.bias\n",
      "blocks.0.attn.query.bias\n",
      "blocks.0.attn.key.weight\n",
      "blocks.1.mlp.2.bias\n",
      "blocks.0.attn.key.bias\n",
      "blocks.3.mlp.0.weight\n",
      "blocks.1.ln1.weight\n",
      "blocks.2.attn.proj.weight\n",
      "tok_emb.weight\n",
      "blocks.3.attn.query.bias\n",
      "blocks.0.mlp.2.weight\n",
      "ln_f.weight\n",
      "blocks.1.attn.key.weight\n",
      "blocks.0.attn.proj.weight\n",
      "blocks.3.attn.value.weight\n",
      "blocks.2.attn.value.bias\n",
      "blocks.1.ln1.bias\n",
      "blocks.2.mlp.2.bias\n",
      "blocks.3.attn.proj.weight\n",
      "blocks.1.attn.key.bias\n",
      "blocks.3.attn.key.bias\n",
      "blocks.1.mlp.0.bias\n",
      "ln_f.bias\n",
      "blocks.2.attn.value.weight\n",
      "blocks.1.attn.proj.weight\n",
      "blocks.2.ln1.bias\n",
      "blocks.0.ln2.weight\n",
      "blocks.2.attn.mask\n",
      "blocks.2.ln1.weight\n",
      "blocks.3.mlp.2.bias\n",
      "blocks.0.attn.proj.bias\n"
     ]
    }
   ],
   "source": [
    "for key in keys(prior_weights)\n",
    "    println(key) \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4abc9007-a910-450c-be22-1ad5e1e051aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Flow failed to import. Set the environment variable D4RL_SUPPRESS_IMPORT_ERROR=1 to suppress this message.\n",
      "No module named 'flow'\n",
      "Warning: CARLA failed to import. Set the environment variable D4RL_SUPPRESS_IMPORT_ERROR=1 to suppress this message.\n",
      "No module named 'carla'\n",
      "pybullet build time: Feb  2 2023 19:56:04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "read_config (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include(\"datasets/sequence.jl\")\n",
    "include(\"models/common.jl\")\n",
    "include(\"models/transformers.jl\")\n",
    "include(\"models/vqvae.jl\")\n",
    "include(\"setup.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1415bbe1-4078-4521-8a92-10d077899177",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ utils/setup ] Reading config: ../config/vqvae.jl:hopper_medium_replay_v2\n",
      "/Users/mehmeteneserciyes/logs_julia/hopper-medium-replay-v2/debug/0 already exists. Proceeding...\n",
      "Made directory /Users/mehmeteneserciyes/logs_julia/hopper-medium-replay-v2/debug/0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"hopper-medium-replay-v2\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "super_args = Dict{String, Any}(\n",
    "    \"dataset\"=> \"hopper-medium-replay-v2\",\n",
    "    \"exp_name\"=> \"debug\",\n",
    "    \"seed\"=> 42,\n",
    "    \"config\"=> \"../config/vqvae.jl\",\n",
    "    \"representation_path\" => \"\", #TODO\n",
    ")\n",
    "\n",
    "args = parser(super_args, experiment=\"plan\")\n",
    "\n",
    "args[\"logbase\"] = expanduser(args[\"logbase\"])\n",
    "args[\"savepath\"] = expanduser(args[\"savepath\"])\n",
    "\n",
    "env_name = occursin(\"-v\", args[\"dataset\"]) ? args[\"dataset\"] : args[\"dataset\"] * \"-v0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08b006fb-dc1e-497b-96bb-fced1597ce22",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ datasets/sequence ] Sequence length: 25 | Step: 1 | Max path length: 1000\n",
      "[ datasets/sequence ] Loading...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mehmeteneserciyes/.julia/conda/3/lib/python3.10/site-packages/gym/logger.py:34: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize(\"%s: %s\" % (\"WARN\", msg % args), \"yellow\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓\n",
      "[ datasets/sequence ] Segmenting..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "load datafile: 100%|███████████████████████████| 11/11 [00:00<00:00, 14.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mCalculating values 100%|█████████████████████████████████| Time: 0:00:04\u001b[39m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_config = Knet.load(joinpath(\"/Users/mehmeteneserciyes/logs_julia/hopper-medium-replay-v2/T-1-42\", \"dataset_config.jld2\"), \"config\")\n",
    "\n",
    "dataset = SequenceDataset(\n",
    "    dataset_config[\"env_name\"];\n",
    "    penalty=dataset_config[\"penalty\"],\n",
    "    sequence_length=dataset_config[\"sequence_length\"], \n",
    "    step=dataset_config[\"step\"], \n",
    "    discount=dataset_config[\"discount\"], \n",
    "    disable_goal=dataset_config[\"disable_goal\"], \n",
    "    normalize_raw=dataset_config[\"normalize_raw\"], \n",
    "    normalize_reward=dataset_config[\"normalize_reward\"],\n",
    "    max_path_length=dataset_config[\"max_path_length\"],\n",
    "    atype=dataset_config[\"atype\"]\n",
    ")\n",
    "\n",
    "obs_dim = dataset.observation_dim\n",
    "act_dim = dataset.action_dim\n",
    "transition_dim = dataset.joined_dim+1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5726e860-4afe-409f-b4c1-fd7d3dba9a52",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Representation model init and weight loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9bc34544-2aaa-46b6-8cb7-e4610f00fb00",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedCollections.OrderedDict{String, Any} with 52 entries:\n",
       "  \"model\"                      => \"VQTransformer\"\n",
       "  \"tag\"                        => \"experiment\"\n",
       "  \"state_conditional\"          => true\n",
       "  \"N\"                          => 100\n",
       "  \"discount\"                   => 0.99\n",
       "  \"n_layer\"                    => 4\n",
       "  \"n_head\"                     => 4\n",
       "  \"n_epochs_ref\"               => 50\n",
       "  \"n_saves\"                    => 3\n",
       "  \"logbase\"                    => \"~/logs_julia/\"\n",
       "  \"device\"                     => \"cuda\"\n",
       "  \"K\"                          => 512\n",
       "  \"latent_step\"                => 3\n",
       "  \"n_embd\"                     => 512\n",
       "  \"trajectory_embd\"            => 512\n",
       "  \"batch_size\"                 => 512\n",
       "  \"learning_rate\"              => 0.0002\n",
       "  \"lr_decay\"                   => false\n",
       "  \"seed\"                       => 42\n",
       "  \"embd_pdrop\"                 => 0.0\n",
       "  \"resid_pdrop\"                => 0.0\n",
       "  \"attn_pdrop\"                 => 0.0\n",
       "  \"step\"                       => 1\n",
       "  \"subsampled_sequence_length\" => 25\n",
       "  \"termination_penalty\"        => -100\n",
       "  ⋮                            => ⋮"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_config = Knet.load(joinpath(\"/Users/mehmeteneserciyes/logs_julia/hopper-medium-replay-v2/T-1-42\", \"model_config.jld2\"), \"config\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90cd41f4-6e72-4d6c-aac9-35f667ecd73e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "representation = VQContinuousVAE(model_config);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b923447-8b04-482b-841c-8a39d3bca278",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# encoder\n",
    "representation.model.embed.w = Param(atype(weights[\"model.embed.weight\"][:cpu]()[:numpy]()))\n",
    "representation.model.embed.b = Param(atype(weights[\"model.embed.bias\"][:cpu]()[:numpy]()))\n",
    "\n",
    "representation.model.pos_emb = Param(atype(permutedims(weights[\"model.pos_emb\"][:cpu]()[:numpy](), (3,2,1))))\n",
    "\n",
    "for i in 1:model_config[\"n_layer\"]\n",
    "    representation.model.encoder.layers[i].ln1.a = Param(atype(weights[\"model.encoder.$(i-1).ln1.weight\"][:cpu]()[:numpy]()))\n",
    "    representation.model.encoder.layers[i].ln1.b = Param(atype(weights[\"model.encoder.$(i-1).ln1.bias\"][:cpu]()[:numpy]()))\n",
    "    representation.model.encoder.layers[i].ln2.a = Param(atype(weights[\"model.encoder.$(i-1).ln2.weight\"][:cpu]()[:numpy]()))\n",
    "    representation.model.encoder.layers[i].ln2.b = Param(atype(weights[\"model.encoder.$(i-1).ln2.bias\"][:cpu]()[:numpy]()))\n",
    "\n",
    "    representation.model.encoder.layers[i].attn.key.w = Param(atype(weights[\"model.encoder.$(i-1).attn.key.weight\"][:cpu]()[:numpy]()))\n",
    "    representation.model.encoder.layers[i].attn.key.b = Param(atype(weights[\"model.encoder.$(i-1).attn.key.bias\"][:cpu]()[:numpy]()))\n",
    "    representation.model.encoder.layers[i].attn.query.w = Param(atype(weights[\"model.encoder.$(i-1).attn.query.weight\"][:cpu]()[:numpy]()))\n",
    "    representation.model.encoder.layers[i].attn.query.b = Param(atype(weights[\"model.encoder.$(i-1).attn.query.bias\"][:cpu]()[:numpy]()))\n",
    "    representation.model.encoder.layers[i].attn.value.w = Param(atype(weights[\"model.encoder.$(i-1).attn.value.weight\"][:cpu]()[:numpy]()))\n",
    "    representation.model.encoder.layers[i].attn.value.b = Param(atype(weights[\"model.encoder.$(i-1).attn.value.bias\"][:cpu]()[:numpy]()))\n",
    "    representation.model.encoder.layers[i].attn.proj.w = Param(atype(weights[\"model.encoder.$(i-1).attn.proj.weight\"][:cpu]()[:numpy]()))\n",
    "    representation.model.encoder.layers[i].attn.proj.b = Param(atype(weights[\"model.encoder.$(i-1).attn.proj.bias\"][:cpu]()[:numpy]()))\n",
    "\n",
    "    representation.model.encoder.layers[i].mlp.layers[1].w = Param(atype(weights[\"model.encoder.$(i-1).mlp.0.weight\"][:cpu]()[:numpy]()))\n",
    "    representation.model.encoder.layers[i].mlp.layers[1].b = Param(atype(weights[\"model.encoder.$(i-1).mlp.0.bias\"][:cpu]()[:numpy]()))\n",
    "    representation.model.encoder.layers[i].mlp.layers[3].w = Param(atype(weights[\"model.encoder.$(i-1).mlp.2.weight\"][:cpu]()[:numpy]()))\n",
    "    representation.model.encoder.layers[i].mlp.layers[3].b = Param(atype(weights[\"model.encoder.$(i-1).mlp.2.bias\"][:cpu]()[:numpy]()))\n",
    "end\n",
    "\n",
    "representation.model.cast_embed.w = Param(atype(weights[\"model.cast_embed.weight\"][:cpu]()[:numpy]()))\n",
    "representation.model.cast_embed.b = Param(atype(weights[\"model.cast_embed.bias\"][:cpu]()[:numpy]()))\n",
    "\n",
    "# Decoder\n",
    "representation.model.latent_mixing.w = Param(atype(weights[\"model.latent_mixing.weight\"][:cpu]()[:numpy]()))\n",
    "representation.model.latent_mixing.b = Param(atype(weights[\"model.latent_mixing.bias\"][:cpu]()[:numpy]()))\n",
    "\n",
    "for i in 1:model_config[\"n_layer\"]\n",
    "    representation.model.decoder.layers[i].ln1.a = Param(atype(weights[\"model.decoder.$(i-1).ln1.weight\"][:cpu]()[:numpy]()))\n",
    "    representation.model.decoder.layers[i].ln1.b = Param(atype(weights[\"model.decoder.$(i-1).ln1.bias\"][:cpu]()[:numpy]()))\n",
    "    representation.model.decoder.layers[i].ln2.a = Param(atype(weights[\"model.decoder.$(i-1).ln2.weight\"][:cpu]()[:numpy]()))\n",
    "    representation.model.decoder.layers[i].ln2.b = Param(atype(weights[\"model.decoder.$(i-1).ln2.bias\"][:cpu]()[:numpy]()))\n",
    "\n",
    "    representation.model.decoder.layers[i].attn.key.w = Param(atype(weights[\"model.decoder.$(i-1).attn.key.weight\"][:cpu]()[:numpy]()))\n",
    "    representation.model.decoder.layers[i].attn.key.b = Param(atype(weights[\"model.decoder.$(i-1).attn.key.bias\"][:cpu]()[:numpy]()))\n",
    "    representation.model.decoder.layers[i].attn.query.w = Param(atype(weights[\"model.decoder.$(i-1).attn.query.weight\"][:cpu]()[:numpy]()))\n",
    "    representation.model.decoder.layers[i].attn.query.b = Param(atype(weights[\"model.decoder.$(i-1).attn.query.bias\"][:cpu]()[:numpy]()))\n",
    "    representation.model.decoder.layers[i].attn.value.w = Param(atype(weights[\"model.decoder.$(i-1).attn.value.weight\"][:cpu]()[:numpy]()))\n",
    "    representation.model.decoder.layers[i].attn.value.b = Param(atype(weights[\"model.decoder.$(i-1).attn.value.bias\"][:cpu]()[:numpy]()))\n",
    "    representation.model.decoder.layers[i].attn.proj.w = Param(atype(weights[\"model.decoder.$(i-1).attn.proj.weight\"][:cpu]()[:numpy]()))\n",
    "    representation.model.decoder.layers[i].attn.proj.b = Param(atype(weights[\"model.decoder.$(i-1).attn.proj.bias\"][:cpu]()[:numpy]()))\n",
    "\n",
    "    representation.model.decoder.layers[i].mlp.layers[1].w = Param(atype(weights[\"model.decoder.$(i-1).mlp.0.weight\"][:cpu]()[:numpy]()))\n",
    "    representation.model.decoder.layers[i].mlp.layers[1].b = Param(atype(weights[\"model.decoder.$(i-1).mlp.0.bias\"][:cpu]()[:numpy]()))\n",
    "    representation.model.decoder.layers[i].mlp.layers[3].w = Param(atype(weights[\"model.decoder.$(i-1).mlp.2.weight\"][:cpu]()[:numpy]()))\n",
    "    representation.model.decoder.layers[i].mlp.layers[3].b = Param(atype(weights[\"model.decoder.$(i-1).mlp.2.bias\"][:cpu]()[:numpy]()))\n",
    "end\n",
    "\n",
    "representation.model.ln_f.a = Param(atype(weights[\"model.ln_f.weight\"][:cpu]()[:numpy]()))\n",
    "representation.model.ln_f.b = Param(atype(weights[\"model.ln_f.bias\"][:cpu]()[:numpy]()))\n",
    "\n",
    "representation.model.predict.w = Param(atype(weights[\"model.predict.weight\"][:cpu]()[:numpy]()))\n",
    "representation.model.predict.b = Param(atype(weights[\"model.predict.bias\"][:cpu]()[:numpy]()))\n",
    "\n",
    "# codebook\n",
    "representation.model.codebook.embedding = Param(atype(weights[\"model.codebook.embedding\"][:cpu]()[:numpy]()'))\n",
    "representation.model.codebook.ema_count = Param(atype(weights[\"model.codebook.ema_count\"][:cpu]()[:numpy]()))\n",
    "representation.model.codebook.ema_w = Param(atype(weights[\"model.codebook.ema_w\"][:cpu]()[:numpy]()'))\n",
    "\n",
    "# padding vector\n",
    "representation.padding_vector = atype(normalize_joined_single(dataset, atype(zeros(representation.transition_dim-1))));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1ec42a-ff2e-42e8-8276-a2da0f6210cd",
   "metadata": {},
   "source": [
    "# TransformerPrior Init and Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c32b6440-7790-4df6-8c2c-7e1664e35df5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ utils/setup ] Reading config: ../config/vqvae.jl:hopper_medium_replay_v2\n",
      "/Users/mehmeteneserciyes/logs_julia/hopper-medium-replay-v2/debug/ already exists. Proceeding...\n",
      "Made directory /Users/mehmeteneserciyes/logs_julia/hopper-medium-replay-v2/debug/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = parser(super_args, experiment=\"train\")\n",
    "args[\"logbase\"] = expanduser(args[\"logbase\"])\n",
    "args[\"savepath\"] = expanduser(args[\"savepath\"])\n",
    "block_size = args[\"subsampled_sequence_length\"] ÷ args[\"latent_step\"]\n",
    "obs_dim = dataset.observation_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7ef05e8-3e3c-41f5-b1ec-53bbbc2873ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_config = deepcopy(args)\n",
    "model_config[\"block_size\"] = block_size\n",
    "model_config[\"observation_dim\"] = obs_dim\n",
    "model_config[\"n_embd\"] = args[\"n_embd\"] * args[\"n_head\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f83ba130-0103-4f76-92cd-158957b32bc3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0f0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# turn off dropout\n",
    "model_config[\"embd_pdrop\"] = 0.0f0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3541e2f-0941-4818-bfd8-a226b6061d56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = TransformerPrior(model_config);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0350caf7-e7ef-47bb-a946-3d829f64d362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder\n",
    "model.tok_emb = Param(atype(prior_weights[\"tok_emb.weight\"][:cpu]()[:numpy]()))\n",
    "model.pos_emb = Param(atype(prior_weights[\"pos_emb\"][:cpu]()[:numpy]()))\n",
    "\n",
    "model.state_emb.w = Param(atype(prior_weights[\"state_emb.weight\"][:cpu]()[:numpy]()))\n",
    "model.state_emb.b = Param(atype(prior_weights[\"state_emb.bias\"][:cpu]()[:numpy]()))\n",
    "\n",
    "for i in 1:model_config[\"n_layer\"]\n",
    "    model.blocks.layers[i].ln1.a = Param(atype(prior_weights[\"blocks.$(i-1).ln1.weight\"][:cpu]()[:numpy]()))\n",
    "    model.blocks.layers[i].ln1.b = Param(atype(prior_weights[\"blocks.$(i-1).ln1.bias\"][:cpu]()[:numpy]()))\n",
    "    model.blocks.layers[i].ln2.a = Param(atype(prior_weights[\"blocks.$(i-1).ln2.weight\"][:cpu]()[:numpy]()))\n",
    "    model.blocks.layers[i].ln2.b = Param(atype(prior_weights[\"blocks.$(i-1).ln2.bias\"][:cpu]()[:numpy]()))\n",
    "\n",
    "    model.blocks.layers[i].attn.key.w = Param(atype(prior_weights[\"blocks.$(i-1).attn.key.weight\"][:cpu]()[:numpy]()))\n",
    "    model.blocks.layers[i].attn.key.b = Param(atype(prior_weights[\"blocks.$(i-1).attn.key.bias\"][:cpu]()[:numpy]()))\n",
    "    model.blocks.layers[i].attn.query.w = Param(atype(prior_weights[\"blocks.$(i-1).attn.query.weight\"][:cpu]()[:numpy]()))\n",
    "    model.blocks.layers[i].attn.query.b = Param(atype(prior_weights[\"blocks.$(i-1).attn.query.bias\"][:cpu]()[:numpy]()))\n",
    "    model.blocks.layers[i].attn.value.w = Param(atype(prior_weights[\"blocks.$(i-1).attn.value.weight\"][:cpu]()[:numpy]()))\n",
    "    model.blocks.layers[i].attn.value.b = Param(atype(prior_weights[\"blocks.$(i-1).attn.value.bias\"][:cpu]()[:numpy]()))\n",
    "    model.blocks.layers[i].attn.proj.w = Param(atype(prior_weights[\"blocks.$(i-1).attn.proj.weight\"][:cpu]()[:numpy]()))\n",
    "    model.blocks.layers[i].attn.proj.b = Param(atype(prior_weights[\"blocks.$(i-1).attn.proj.bias\"][:cpu]()[:numpy]()))\n",
    "\n",
    "    model.blocks.layers[i].mlp.layers[1].w = Param(atype(prior_weights[\"blocks.$(i-1).mlp.0.weight\"][:cpu]()[:numpy]()))\n",
    "    model.blocks.layers[i].mlp.layers[1].b = Param(atype(prior_weights[\"blocks.$(i-1).mlp.0.bias\"][:cpu]()[:numpy]()))\n",
    "    model.blocks.layers[i].mlp.layers[3].w = Param(atype(prior_weights[\"blocks.$(i-1).mlp.2.weight\"][:cpu]()[:numpy]()))\n",
    "    model.blocks.layers[i].mlp.layers[3].b = Param(atype(prior_weights[\"blocks.$(i-1).mlp.2.bias\"][:cpu]()[:numpy]()))\n",
    "end\n",
    "\n",
    "model.ln_f.a = Param(atype(prior_weights[\"ln_f.weight\"][:cpu]()[:numpy]()))\n",
    "model.ln_f.b = Param(atype(prior_weights[\"ln_f.bias\"][:cpu]()[:numpy]()))\n",
    "\n",
    "model.head.w = Param(atype(prior_weights[\"head.weight\"][:cpu]()[:numpy]())); # no bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b5ab0a-b161-458e-8682-e60251fa9a40",
   "metadata": {},
   "source": [
    "# Test same results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b298c2-a175-4529-a9cc-696b04c0ff32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.5",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
