{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99505f95-002e-4afd-a53c-4ab599a0af3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Flow failed to import. Set the environment variable D4RL_SUPPRESS_IMPORT_ERROR=1 to suppress this message.\n",
      "No module named 'flow'\n",
      "Warning: CARLA failed to import. Set the environment variable D4RL_SUPPRESS_IMPORT_ERROR=1 to suppress this message.\n",
      "No module named 'carla'\n",
      "pybullet build time: Nov 12 2022 16:05:06\n"
     ]
    }
   ],
   "source": [
    "using ArgParse: ArgParseSettings, @add_arg_table!, parse_args\n",
    "using Statistics: mean\n",
    "using Printf\n",
    "using Knet\n",
    "\n",
    "include(\"../latentplan/LPCore.jl\")\n",
    "include(\"../latentplan/setup.jl\")\n",
    "using .LPCore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a234020-95ea-4f05-9efb-748d1b1518e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vq_train (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losssum(prediction) = mean(prediction[2] + prediction[3] + prediction[4])\n",
    "\n",
    "function vq_train(config, model::VQContinuousVAE, dataset; n_epochs=1, log_freq=100)\n",
    "    # set optimizers\n",
    "    opt_decay = AdamW(lr=config[\"learning_rate\"], beta1=config[\"betas\"][1], beta2=config[\"betas\"][2], weight_decay=config[\"weight_decay\"], gclip=config[\"grad_norm_clip\"])\n",
    "    opt_no_decay = AdamW(lr=config[\"learning_rate\"], beta1=config[\"betas\"][1], beta2=config[\"betas\"][2], weight_decay=0.0, gclip=config[\"grad_norm_clip\"])\n",
    "\n",
    "    for p in paramlist_decay(model)\n",
    "        p.opt = clone(opt_decay)\n",
    "    end\n",
    "    for p in paramlist_no_decay(model)\n",
    "        p.opt = clone(opt_no_decay)\n",
    "    end\n",
    "\n",
    "    n_tokens = 0\n",
    "    loader = DataLoader(dataset; shuffle=true, batch_size=config[\"batch_size\"])\n",
    "\n",
    "    for epoch in 1:n_epochs\n",
    "        losses = []\n",
    "        for (it, batch) in enumerate(loader)\n",
    "            y = batch[end-1]\n",
    "            n_tokens += cumprod(size(y))\n",
    "\n",
    "            if n_tokens < config[\"warmup_tokens\"]\n",
    "                # linear warmup\n",
    "                lr_mult = float(n_tokens) / float(max(1, config[\"warmup_tokens\"]))\n",
    "            else\n",
    "                # cosine learning rate decay\n",
    "                progress = float(n_tokens - config[\"warmup_tokens\"]) / float(\n",
    "                    max(1, config[\"final_tokens\"] - config[\"warmup_tokens\"])\n",
    "                )\n",
    "                lr_mult = max(0.1, 0.5 * (1.0 + cos(pi * progress)))\n",
    "            end\n",
    "\n",
    "            if config[\"lr_decay\"]\n",
    "                lr = config[\"learning_rate\"] * lr_mult\n",
    "                # TODO: param_group learning rate\n",
    "                for p in paramlist(model)\n",
    "                    p.opt.lr = lr\n",
    "                end\n",
    "            else\n",
    "                lr = config[\"learning_rate\"]\n",
    "            end\n",
    "\n",
    "            # forward the model\n",
    "            total_loss = @diff losssum(model(batch...))\n",
    "            push!(losses, value(total_loss))\n",
    "            for p in paramlist(model)\n",
    "                update!(p, grad(total_loss, p))\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c45cc77-53d5-46e6-841c-700f798a2b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ utils/setup ] Reading config: ../config/vqvae.jl:halfcheetah_medium_expert_v2\n",
      "/Users/enes/logs/halfcheetah-medium-expert-v2/debug/ already exists. Proceeding...\n",
      "Made directory/Users/enes/logs/halfcheetah-medium-expert-v2/debug/\n"
     ]
    }
   ],
   "source": [
    "s = ArgParseSettings()\n",
    "@add_arg_table! s begin\n",
    "    \"--dataset\"\n",
    "        help = \"which environment to use\"\n",
    "        arg_type = String\n",
    "        default = \"halfcheetah-medium-expert-v2\"\n",
    "    \"--exp_name\"\n",
    "        help = \"name of the experiment\"\n",
    "        arg_type = String\n",
    "        default = \"debug\"\n",
    "    \"--seed\"\n",
    "        help = \"seed\"\n",
    "        arg_type = Int\n",
    "        default = 42\n",
    "    \"--config\"\n",
    "        help = \"relative jl file path with configurations\"\n",
    "        arg_type = String\n",
    "        default = \"../config/vqvae.jl\"\n",
    "end\n",
    "\n",
    "#######################\n",
    "######## setup ########\n",
    "#######################\n",
    "\n",
    "super_args = parse_args([], s)\n",
    "args = parser(super_args, experiment=\"train\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29113ae2-6d5f-4736-ba8e-55b5bf781d55",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b8e93ff-bd06-49f7-8685-74b32a498d6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ datasets/sequence ] Sequence length: 25 | Step: 1 | Max path length: 1000\n",
      "[ datasets/sequence ] Loading...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/enes/.julia/conda/3/lib/python3.10/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "load datafile: 100%|█████████████████████████████| 9/9 [00:05<00:00,  1.65it/s]\n",
      "\u001b[32mGenerating dataset 100%|█████████████████████████████████| Time: 0:00:00\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓\n",
      "[ datasets/sequence ] Segmenting...\n",
      "✓\n",
      "Dataset size: 48 |\n",
      "    Joined dim: 26\n",
      "    observation: 17, action: 6 | Block size: 650"
     ]
    }
   ],
   "source": [
    "env_name = occursin(\"-v\", args[\"dataset\"]) ? args[\"dataset\"] : args[\"dataset\"] * \"-v0\"\n",
    "\n",
    "# env params\n",
    "sequence_length = args[\"subsampled_sequence_length\"] * args[\"step\"]\n",
    "args[\"logbase\"] = expanduser(args[\"logbase\"])\n",
    "args[\"savepath\"] = expanduser(args[\"savepath\"])\n",
    "if !isdir(args[\"savepath\"])\n",
    "    mkpath(args[\"savepath\"])\n",
    "end\n",
    "\n",
    "dataset = SequenceDataset(\n",
    "    env_name;\n",
    "    penalty=args[\"termination_penalty\"], \n",
    "    sequence_length=sequence_length, \n",
    "    step=args[\"step\"], \n",
    "    discount=args[\"discount\"], \n",
    "    disable_goal=args[\"disable_goal\"], \n",
    "    normalize_raw=args[\"normalize\"], \n",
    "    normalize_reward=args[\"normalize_reward\"],\n",
    "    max_path_length=args[\"max_path_length\"],\n",
    ")\n",
    "\n",
    "obs_dim = dataset.observation_dim\n",
    "act_dim = dataset.action_dim\n",
    "if args[\"task_type\"] == \"locomotion\"\n",
    "    transition_dim = obs_dim+act_dim+3\n",
    "else\n",
    "    transition_dim = 128+act_dim+3\n",
    "end\n",
    "\n",
    "block_size = args[\"subsampled_sequence_length\"] * transition_dim # total number of dimensionalities for a maximum length sequence (T)\n",
    "\n",
    "print(\n",
    "    \"Dataset size: $(length(dataset)) |\n",
    "    Joined dim: $transition_dim\n",
    "    observation: $obs_dim, action: $act_dim | Block size: $block_size\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1b6101-cf07-45dc-89a7-d192d2ea9a62",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5fc6349f-b918-401f-903f-cd387c256cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = deepcopy(args)\n",
    "model_config[\"block_size\"] = block_size\n",
    "model_config[\"observation_dim\"] = obs_dim\n",
    "model_config[\"action_dim\"] = act_dim\n",
    "model_config[\"transition_dim\"] = transition_dim\n",
    "model_config[\"n_embd\"] = args[\"n_embd\"] * args[\"n_head\"]\n",
    "model_config[\"vocab_size\"] = args[\"N\"]\n",
    "\n",
    "model = VQContinuousVAE(model_config);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff4aaf64-be20-4670-9037-fa17296c4aeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "139"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length(paramlist(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7bc4096-3c89-401f-b04e-fd5efdf4cbcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 - 512\n",
      "2 - 512\n",
      "3 - 512\n",
      "4 - 512\n",
      "5 - 262144\n",
      "6 - 512\n",
      "7 - 262144\n",
      "8 - 512\n",
      "9 - 262144\n",
      "10 - 512\n",
      "11 - 262144\n",
      "12 - 512\n",
      "13 - 1048576\n",
      "14 - 2048\n",
      "15 - 1048576\n",
      "16 - 512\n",
      "17 - 512\n",
      "18 - 512\n",
      "19 - 512\n",
      "20 - 512\n",
      "21 - 262144\n",
      "22 - 512\n",
      "23 - 262144\n",
      "24 - 512\n",
      "25 - 262144\n",
      "26 - 512\n",
      "27 - 262144\n",
      "28 - 512\n",
      "29 - 1048576\n",
      "30 - 2048\n",
      "31 - 1048576\n",
      "32 - 512\n",
      "33 - 512\n",
      "34 - 512\n",
      "35 - 512\n",
      "36 - 512\n",
      "37 - 262144\n",
      "38 - 512\n",
      "39 - 262144\n",
      "40 - 512\n",
      "41 - 262144\n",
      "42 - 512\n",
      "43 - 262144\n",
      "44 - 512\n",
      "45 - 1048576\n",
      "46 - 2048\n",
      "47 - 1048576\n",
      "48 - 512\n",
      "49 - 512\n",
      "50 - 512\n",
      "51 - 512\n",
      "52 - 512\n",
      "53 - 262144\n",
      "54 - 512\n",
      "55 - 262144\n",
      "56 - 512\n",
      "57 - 262144\n",
      "58 - 512\n",
      "59 - 262144\n",
      "60 - 512\n",
      "61 - 1048576\n",
      "62 - 2048\n",
      "63 - 1048576\n",
      "64 - 512\n",
      "65 - 512\n",
      "66 - 512\n",
      "67 - 512\n",
      "68 - 512\n",
      "69 - 262144\n",
      "70 - 512\n",
      "71 - 262144\n",
      "72 - 512\n",
      "73 - 262144\n",
      "74 - 512\n",
      "75 - 262144\n",
      "76 - 512\n",
      "77 - 1048576\n",
      "78 - 2048\n",
      "79 - 1048576\n",
      "80 - 512\n",
      "81 - 512\n",
      "82 - 512\n",
      "83 - 512\n",
      "84 - 512\n",
      "85 - 262144\n",
      "86 - 512\n",
      "87 - 262144\n",
      "88 - 512\n",
      "89 - 262144\n",
      "90 - 512\n",
      "91 - 262144\n",
      "92 - 512\n",
      "93 - 1048576\n",
      "94 - 2048\n",
      "95 - 1048576\n",
      "96 - 512\n",
      "97 - 512\n",
      "98 - 512\n",
      "99 - 512\n",
      "100 - 512\n",
      "101 - 262144\n",
      "102 - 512\n",
      "103 - 262144\n",
      "104 - 512\n",
      "105 - 262144\n",
      "106 - 512\n",
      "107 - 262144\n",
      "108 - 512\n",
      "109 - 1048576\n",
      "110 - 2048\n",
      "111 - 1048576\n",
      "112 - 512\n",
      "113 - 512\n",
      "114 - 512\n",
      "115 - 512\n",
      "116 - 512\n",
      "117 - 262144\n",
      "118 - 512\n",
      "119 - 262144\n",
      "120 - 512\n",
      "121 - 262144\n",
      "122 - 512\n",
      "123 - 262144\n",
      "124 - 512\n",
      "125 - 1048576\n",
      "126 - 2048\n",
      "127 - 1048576\n",
      "128 - 512\n",
      "129 - 13312\n",
      "130 - 512\n",
      "131 - 13312\n",
      "132 - 26\n",
      "133 - 13312\n",
      "134 - 26\n",
      "135 - 270848\n",
      "136 - 512\n",
      "137 - 512\n",
      "138 - 512\n",
      "139 - 13312\n",
      "Number of parameters in model: 25545268"
     ]
    }
   ],
   "source": [
    "num_params = 0\n",
    "for (i, param) in enumerate(paramlist(model))\n",
    "    println(i, \" - \", length(param))\n",
    "    num_params += length(param)\n",
    "end\n",
    "print(\"Number of parameters in model: \", num_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9742e877-3208-4511-84f8-a69e35523153",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.0",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
