{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99505f95-002e-4afd-a53c-4ab599a0af3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Flow failed to import. Set the environment variable D4RL_SUPPRESS_IMPORT_ERROR=1 to suppress this message.\n",
      "No module named 'flow'\n",
      "Warning: CARLA failed to import. Set the environment variable D4RL_SUPPRESS_IMPORT_ERROR=1 to suppress this message.\n",
      "No module named 'carla'\n",
      "pybullet build time: Nov 12 2022 16:05:06\n"
     ]
    }
   ],
   "source": [
    "using ArgParse: ArgParseSettings, @add_arg_table!, parse_args\n",
    "using Statistics: mean\n",
    "using Printf\n",
    "using Knet\n",
    "\n",
    "include(\"../latentplan/LPCore.jl\")\n",
    "include(\"../latentplan/setup.jl\")\n",
    "using .LPCore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a234020-95ea-4f05-9efb-748d1b1518e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vq_train (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losssum(prediction) = mean(prediction[2] + prediction[3] + prediction[4])\n",
    "\n",
    "function vq_train(config, model::VQContinuousVAE, dataset; n_epochs=1, log_freq=100)\n",
    "    # set optimizers\n",
    "    opt_decay = AdamW(lr=config[\"learning_rate\"], beta1=config[\"betas\"][1], beta2=config[\"betas\"][2], weight_decay=config[\"weight_decay\"], gclip=config[\"grad_norm_clip\"])\n",
    "    opt_no_decay = AdamW(lr=config[\"learning_rate\"], beta1=config[\"betas\"][1], beta2=config[\"betas\"][2], weight_decay=0.0, gclip=config[\"grad_norm_clip\"])\n",
    "\n",
    "    for p in paramlist_decay(model)\n",
    "        p.opt = clone(opt_decay)\n",
    "    end\n",
    "    for p in paramlist_no_decay(model)\n",
    "        p.opt = clone(opt_no_decay)\n",
    "    end\n",
    "\n",
    "    n_tokens = 0\n",
    "    loader = DataLoader(dataset; shuffle=true, batch_size=config[\"batch_size\"])\n",
    "\n",
    "    for epoch in 1:n_epochs\n",
    "        losses = []\n",
    "        for (it, batch) in enumerate(loader)\n",
    "            y = batch[end-1]\n",
    "            n_tokens += cumprod(size(y))\n",
    "\n",
    "            if n_tokens < config[\"warmup_tokens\"]\n",
    "                # linear warmup\n",
    "                lr_mult = float(n_tokens) / float(max(1, config[\"warmup_tokens\"]))\n",
    "            else\n",
    "                # cosine learning rate decay\n",
    "                progress = float(n_tokens - config[\"warmup_tokens\"]) / float(\n",
    "                    max(1, config[\"final_tokens\"] - config[\"warmup_tokens\"])\n",
    "                )\n",
    "                lr_mult = max(0.1, 0.5 * (1.0 + cos(pi * progress)))\n",
    "            end\n",
    "\n",
    "            if config[\"lr_decay\"]\n",
    "                lr = config[\"learning_rate\"] * lr_mult\n",
    "                # TODO: param_group learning rate\n",
    "                for p in paramlist(model)\n",
    "                    p.opt.lr = lr\n",
    "                end\n",
    "            else\n",
    "                lr = config[\"learning_rate\"]\n",
    "            end\n",
    "\n",
    "            # forward the model\n",
    "            total_loss = @diff losssum(model(batch...))\n",
    "            push!(losses, value(total_loss))\n",
    "            for p in paramlist(model)\n",
    "                update!(p, grad(total_loss, p))\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c45cc77-53d5-46e6-841c-700f798a2b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ utils/setup ] Reading config: ../config/vqvae.jl:halfcheetah_medium_expert_v2\n",
      "/Users/enes/logs/halfcheetah-medium-expert-v2/debug/ already exists. Proceeding...\n",
      "Made directory/Users/enes/logs/halfcheetah-medium-expert-v2/debug/\n"
     ]
    }
   ],
   "source": [
    "s = ArgParseSettings()\n",
    "@add_arg_table! s begin\n",
    "    \"--dataset\"\n",
    "        help = \"which environment to use\"\n",
    "        arg_type = String\n",
    "        default = \"halfcheetah-medium-expert-v2\"\n",
    "    \"--exp_name\"\n",
    "        help = \"name of the experiment\"\n",
    "        arg_type = String\n",
    "        default = \"debug\"\n",
    "    \"--seed\"\n",
    "        help = \"seed\"\n",
    "        arg_type = Int\n",
    "        default = 42\n",
    "    \"--config\"\n",
    "        help = \"relative jl file path with configurations\"\n",
    "        arg_type = String\n",
    "        default = \"../config/vqvae.jl\"\n",
    "end\n",
    "\n",
    "#######################\n",
    "######## setup ########\n",
    "#######################\n",
    "\n",
    "super_args = parse_args([], s)\n",
    "args = parser(super_args, experiment=\"train\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29113ae2-6d5f-4736-ba8e-55b5bf781d55",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b8e93ff-bd06-49f7-8685-74b32a498d6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ datasets/sequence ] Sequence length: 25 | Step: 1 | Max path length: 1000\n",
      "[ datasets/sequence ] Loading...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/enes/.julia/conda/3/lib/python3.10/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "load datafile: 100%|█████████████████████████████| 9/9 [00:07<00:00,  1.28it/s]\n",
      "\u001b[32mGenerating dataset 100%|█████████████████████████████████| Time: 0:00:00\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓\n",
      "[ datasets/sequence ] Segmenting...\n",
      "✓\n",
      "Dataset size: 48 |\n",
      "    Joined dim: 26\n",
      "    observation: 17, action: 6 | Block size: 650"
     ]
    }
   ],
   "source": [
    "env_name = occursin(\"-v\", args[\"dataset\"]) ? args[\"dataset\"] : args[\"dataset\"] * \"-v0\"\n",
    "\n",
    "# env params\n",
    "sequence_length = args[\"subsampled_sequence_length\"] * args[\"step\"]\n",
    "args[\"logbase\"] = expanduser(args[\"logbase\"])\n",
    "args[\"savepath\"] = expanduser(args[\"savepath\"])\n",
    "if !isdir(args[\"savepath\"])\n",
    "    mkpath(args[\"savepath\"])\n",
    "end\n",
    "\n",
    "dataset = SequenceDataset(\n",
    "    env_name;\n",
    "    penalty=args[\"termination_penalty\"], \n",
    "    sequence_length=sequence_length, \n",
    "    step=args[\"step\"], \n",
    "    discount=args[\"discount\"], \n",
    "    disable_goal=args[\"disable_goal\"], \n",
    "    normalize_raw=args[\"normalize\"], \n",
    "    normalize_reward=args[\"normalize_reward\"],\n",
    "    max_path_length=args[\"max_path_length\"],\n",
    ")\n",
    "\n",
    "obs_dim = dataset.observation_dim\n",
    "act_dim = dataset.action_dim\n",
    "if args[\"task_type\"] == \"locomotion\"\n",
    "    transition_dim = obs_dim+act_dim+3\n",
    "else\n",
    "    transition_dim = 128+act_dim+3\n",
    "end\n",
    "\n",
    "block_size = args[\"subsampled_sequence_length\"] * transition_dim # total number of dimensionalities for a maximum length sequence (T)\n",
    "\n",
    "print(\n",
    "    \"Dataset size: $(length(dataset)) |\n",
    "    Joined dim: $transition_dim\n",
    "    observation: $obs_dim, action: $act_dim | Block size: $block_size\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1b6101-cf07-45dc-89a7-d192d2ea9a62",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fc6349f-b918-401f-903f-cd387c256cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = deepcopy(args)\n",
    "model_config[\"block_size\"] = block_size\n",
    "model_config[\"observation_dim\"] = obs_dim\n",
    "model_config[\"action_dim\"] = act_dim\n",
    "model_config[\"transition_dim\"] = transition_dim\n",
    "model_config[\"n_embd\"] = args[\"n_embd\"] * args[\"n_head\"]\n",
    "model_config[\"vocab_size\"] = args[\"N\"]\n",
    "\n",
    "model = VQContinuousVAE(model_config);\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3419f783-14a0-478b-b100-7fab7868860d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7bc4096-3c89-401f-b04e-fd5efdf4cbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# component = model.model.ln_f\n",
    "# num_params = 0\n",
    "# for (i, param) in enumerate(paramlist(model))\n",
    "#     println(i, \" - \", length(param))\n",
    "#     num_params += length(param)\n",
    "# end\n",
    "# print(\"Number of parameters in model: \", num_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f867b8-80be-4ec0-bbb3-fc5ea32af98e",
   "metadata": {},
   "source": [
    "# Train process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d008afc-a355-4bc2-b7ae-6f0b3580660b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(dataset; shuffle=true, batch_size=args[\"batch_size\"])\n",
    "batch = nothing\n",
    "for (it, b) in enumerate(loader)\n",
    "    batch = b\n",
    "    break\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2cd42e26-42b9-4ca0-b2bc-0b39d724e3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_inputs, targets, mask, terminals = batch;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c58c8b0a-22a5-48f5-8ec0-455f13398a3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 24, 48)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_dimension, t, b = size(joined_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36d8d845-e9d1-481f-b045-35c8499a1f5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25-element Vector{Float64}:\n",
       "  1.3586551130902185\n",
       "  0.228389940535605\n",
       "  0.7069261656678192\n",
       "  1.3224555746290494\n",
       "  2.506223180702559\n",
       "  0.3803132917548237\n",
       "  0.5203201193541377\n",
       "  0.17306247156993976\n",
       " -2.0574827651805627\n",
       "  0.13590436198433534\n",
       " -0.06275258940279395\n",
       " -0.04819511565385873\n",
       " -0.007849192285634327\n",
       " -0.07929695236955941\n",
       "  0.02990876731896082\n",
       "  0.005835718021037472\n",
       "  0.017623983572789888\n",
       "  0.21693206086149935\n",
       "  0.9879023298435688\n",
       "  1.4429752437532077\n",
       "  0.3731244195973748\n",
       "  0.4378495563353325\n",
       "  0.15207652016219186\n",
       " -1.8588657195968\n",
       " -2.1642992947245396"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.padding_vector = normalize_joined_single(dataset, zeros(model.transition_dim-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484122d0-063b-4ba3-8672-da173927ea8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.0",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
